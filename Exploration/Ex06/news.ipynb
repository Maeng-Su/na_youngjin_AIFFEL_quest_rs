{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "284fcc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5\n",
      "2.6.0\n",
      "1.3.3\n",
      "1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import nltk\n",
    "import tensorflow\n",
    "import summa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "nltk.download('stopwords')\n",
    "print(nltk.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(pd.__version__)\n",
    "print(version('summa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ffb144d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Rajkummar Rao to replace SRK in Rakesh Sharma ...</td>\n",
       "      <td>Actor Rajkummar Rao will replace Shah Rukh Kha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89498</th>\n",
       "      <td>Sharapova's wildcards driven by media coverage...</td>\n",
       "      <td>World number one Andy Murray has claimed that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72895</th>\n",
       "      <td>FreshWorks buys Chennai-based Zarget in 9th ac...</td>\n",
       "      <td>Customer engagement platform Freshworks, forme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "283    Rajkummar Rao to replace SRK in Rakesh Sharma ...   \n",
       "89498  Sharapova's wildcards driven by media coverage...   \n",
       "72895  FreshWorks buys Chennai-based Zarget in 9th ac...   \n",
       "\n",
       "                                                    text  \n",
       "283    Actor Rajkummar Rao will replace Shah Rukh Kha...  \n",
       "89498  World number one Andy Murray has claimed that ...  \n",
       "72895  Customer engagement platform Freshworks, forme...  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dac8c6",
   "metadata": {},
   "source": [
    "텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b1771648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. 데이터 전처리하기 (추상적 요약)   \n",
    "# 실습에서 사용된 전처리를 참고하여 각자 필요하다고 생각하는 전처리를 추가 사용하여 텍스트를 정규화 또는 정제해 보세요. \n",
    "# 만약, 불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해 보세요. \n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bfb5519a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total len: 98401\n"
     ]
    }
   ],
   "source": [
    "print('Total len:', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8318085c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98360 98280\n"
     ]
    }
   ],
   "source": [
    "#  중복 샘플이므로 제거 필요\n",
    "print(data['text'].nunique(),  data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ce67711b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9decef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ee5ecc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "#텍스트 정규화와 불용어 제거\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "183447ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "#     sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub(r'[^\\w\\s]', ' ', sentence)\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (headline)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "625d3cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "headlines: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "# temp_headlines = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "# print(\"text: \", preprocess_sentence(temp_text))\n",
    "# print(\"headlines:\", preprocess_sentence(temp_headlines, False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "66106739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wasfor 에 대한 처리 추가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9f841f13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_text = []\n",
    "clean_head = []\n",
    "\n",
    "for text in data['text']:\n",
    "    text = preprocess_sentence(text,False)\n",
    "    clean_text.append(text)\n",
    "for head in data['headlines']:\n",
    "    head = preprocess_sentence(head,False)\n",
    "    clean_head.append(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "65d19099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text preprocess:  ['saurav kant an alumnus of upgrad and iiit pg program in machine learning and artificial intelligence was sr systems engineer at infosys with almost years of work experience the program and upgrad 360 degree career support helped him transition to data scientist at tech mahindra with 90 salary hike upgrad online power learning has powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance to win free food from swiggy for one year pranav kaushik delhi techie bagged this reward after spending 2000 cred coins users get one cred coin per rupee of bill paid which can be used to avail rewards from brands like ixigo bookmyshow ubereats cult fit and more', 'new zealand defeated india by wickets in the fourth odi at hamilton on thursday to win their first match of the five match odi series india lost an international match under rohit sharma captaincy after 12 consecutive victories dating back to march 2018 the match witnessed india getting all out for 92 their seventh lowest total in odi cricket history', 'with aegon life iterm insurance plan customers can enjoy tax benefits on your premiums paid and save up to â¹46 800 on taxes the plan provides life cover up to the age of 100 years also customers have options to insure against critical illnesses disability and accidental death benefit rider with life cover up to the age of 80 years', 'speaking about the sexual harassment allegations against rajkumar hirani sonam kapoor said have known hirani for many years what if it is not true the metoo movement will get derailed in the metoo movement always believe woman but in this case we need to reserve our judgment she added hirani has been accused by an assistant who worked in sanju']\n",
      "headlines preprocess:  ['upgrad learner switches to career in ml al with 90 salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india 12 match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n"
     ]
    }
   ],
   "source": [
    "print(\"text preprocess: \", clean_text[:5])\n",
    "print(\"headlines preprocess: \", clean_head[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "43b1cd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty 샘플이 생겼는지 확인\n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_head\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "333c96ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 74\n",
      "텍스트의 평균 길이 : 57.51595160634404\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.592303782025214\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAc3UlEQVR4nO3df5BV5Z3n8feHBpsARujIMCh0mlJjOnYSSZj8UJKRiLNmJqMmRaXSk1gk25EiO9ObLGTF2FUbU5umZDYkZnum0ivByCROJw7RlU3NJCK0a7UaJ2gIQTuOv1pBUUj4pYhIw3f/uAem6e2mb/+495x77+dVdavvec65fb8oh899znnu8ygiMDMzy5pxaRdgZmY2EAeUmZllkgPKzMwyyQFlZmaZ5IAyM7NMckCZmVkmOaDMzCyTHFAlQNJrfR7HJR3us/3ZEfy+yyTtLEStZoUkab6khyQdkLRX0oOS/iTtuqwwxqddgA0tIqaceC6pB/hiRNyXXkVmxSfprcDPgC8BdwJnAB8BjqRZ13BIEqCIOJ52LaXAPagSJmmcpBskPSPpD5LulFST7PuepJ/2OXaVpE2SJgP/ApzTpxd2Tlp/BrNheAdARHRExLGIOBwR90bENkk3SfrRiQMl1UkKSeOT7fslfTPpfb0m6f9IepukOyQdlPQrSXV9Xh+S/pOkpyS9Kum/Szovef3B5Fw7Izl2mqSfSdojaV/yfFaf33W/pFZJDwKvA8slPdr3DyZpmaR7CvpfrwQ5oEpbM3AN8KfAOcA+4O+TfcuBd0v6vKSPAE3A4og4BHwceCkipiSPl4pfutmw/RtwTNI6SR+XNG2Yr/8McC1wLnAe8DDwA6AG6Aa+3u/4/wC8H/gQcD1wK/A5YDbQADQmx41Lfs/bgVrgMPB3/X7XtcAS4EzgfwJzJNX32/8Pw/zzlD0HVGlbCrRExM6IOALcBCySND4iXif3l/7bwI+A5ojwfScrWRFxEJgPBLAG2CNpg6QZef6KH0TEMxFxgNxVhGci4r6I6AX+CZjb7/i/jYiDEfE4sB24NyKe7fP6uUldf4iIn0bE6xHxKtBK7kNjX7dHxOMR0Zucqz8hF3ZIugioI3f50vpwQJW2twN3S9ovaT+5T4HHgBkAEfEI8CwgctfszUpaRHRHxOcjYha5Xsw5wC15vvyVPs8PD7A95dTD8zte0iRJ/0vS85IOAg8AUyVV9Tl+R7/fvQ74q+Se1LXAnUlwWR8OqNK2A/h4REzt85gYES8CSPproBp4idwlihM8hb2VvIj4HXA7uaA6BEzqs/uPi1jKcuBC4IMR8Vbgo0m7+hxzyjkXEb8E3iQ3yOOvgB8Woc6S44Aqbe1Aq6S3A0iaLunq5Pk7gG+Su4xwLXC9pIuT170CvE3SWcUv2WxkJL1T0vITAxAkzSZ3H+iXwFbgo5Jqk7/XXytiaWeS61HtTwYp9b+XNZh/IHev6mhEdBWquFLmgCpt3wU2APdKepXcifrBZOTSj4BVEfGbiHgKuBH4oaTq5JNnB/BscnnQo/isFLwKfBB4RNIhcn/ftwPLI2Ijufs624BHKe79nFuAtwC/T2r6eZ6v+yG53t+PhjqwUskLFpqZFZ+ktwC7gfclHyKtH/egzMzS8SXgVw6nwXkmCTOzIktmhBG57zHaIHyJz8zMMsmX+MzMLJOKeonv7LPPjrq6umK+pVnBPProo7+PiOnFfl+fR1ZuBjuXihpQdXV1bNmypZhvaVYwkp5P4319Hlm5Gexc8iU+MzPLJAeUmZllkgPKzMwyyQFlZmaZ5IAyM7NMckCZmVkmOaDKSEdHBw0NDVRVVdHQ0EBHR0faJVkfkm6TtFvS9n7tzZJ+J+lxSX+bVn3276ZMmYKkk48pU/qvZWjF4IAqEx0dHbS0tNDW1sYbb7xBW1sbLS0tDqlsuR24sm+DpAXA1cB7I+Ii4Fsp1GV9TJkyhUOHDlFXV8fTTz9NXV0dhw4dckilwAFVJlpbW1m7di0LFixgwoQJLFiwgLVr19La2pp2aZaIiAeAvf2avwTcfGK574jYXfTC7BQnwum5557jvPPO47nnnjsZUlZcDqgy0d3dzfz5809pmz9/Pt3d3SlVZHl6B/ARSY9I+r+S/mSggyQtkbRF0pY9e/YUucTKc999951224rDAVUm6uvr6eo6ddXorq4u6uvrU6rI8jQeqAE+BPxX4E5J6n9QRNwaEfMiYt706UWf/q/iLFy48LTbVhwOqDLR0tJCU1MTnZ2dHD16lM7OTpqammhpaUm7NDu9ncBdkfOvwHHg7JRrqmiTJ0+mp6eHOXPm8MwzzzBnzhx6enqYPHly2qVVHC9YWCYaGxsBaG5upru7m/r6elpbW0+2W2b9b2AB0CnpHcAZwO9TrajCvfbaa0yZMoWenh7OP/98IBdar732WsqVVR4HVBlpbGx0IGWYpA7gMuBsSTuBrwO3AbclQ8/fBBaHVxFNncMoGxxQZkUSEYN9evhcUQsxKxG+B1VGmpubmThxIpKYOHEizc3NaZdkZjZiDqgy0dzcTHt7OytXruTQoUOsXLmS9vZ2h5SZlawhA0rShZK29nkclPQVSTWSNkp6Kvk5rRgF28DWrFnDqlWrWLZsGZMmTWLZsmWsWrWKNWvWpF2amdmIDBlQEfFkRFwcERcD7wdeB+4GbgA2RcQFwKZk21Jy5MgRnnzyyVMu8T355JMcOXIk7dLMzEZkuJf4LgeeiYjnyc0fti5pXwdcM4Z12TBVVVWxZs2aUy7xrVmzhqqqqrRLMzMbkeGO4vsMcGL20RkRsSt5/jIwY8yqsmGLCPpPQCAJj1g2G74BJvPwuZSCvHtQks4ArgL+qf++5HsbA/7f8xxixXH8+HHGjRvH8uXLmTx5MsuXL2fcuHEcP3487dLMSkrfcPrkJz85YLsVx3Au8X0ceCwiXkm2X5E0EyD5OeAszJ5DrHh6e3tPWSKgt7c37ZLMSlZEcNddd7nnlKLhBFQj/355D2ADsDh5vhi4Z6yKspE7MT1LT09P2qWYlay+PaeBtq048gooSZOBK4C7+jTfDFwh6SlgYbJtZlby7r777tNuW3HkFVARcSgi3hYRB/q0/SEiLo+ICyJiYUT0X4jNUhARJx9mNnKS+NSnPuV7TynyXHxlxieT2ej0HRHbt+fkD33F54AyM+vHYZQNnouvDK1fvz7tEszMRs0BVYYWLVqUdglmZqPmS3xlpu+lCd+PMrNS5h5UmfHIIzMrF+5BlajTBVD/72z0P9Y3gM2sFDigStTpQsaTxJpZOfAlPrMikXSbpN2Stg+wb7mkkHR2GrWZZZEDyqx4bgeu7N8oaTbwZ8ALxS7ILMscUGZFEhEPAANNCfYd4HoGWbLGrFL5HpRZiiRdDbwYEb853cAXSUuAJQC1tbVFqq4yjHTEq+/zFp57UGYpkTQJuBH4b0Md63XVCqfvBMv9H6fbb4XngDJLz3nAHOA3knqAWcBjkv441arMMsKX+MxSEhG/Bf7oxHYSUvMi4vepFWWWIe5BmRWJpA7gYeBCSTslNaVdk1mWuQdlViQR0TjE/roilWJWEtyDMjOzTHJAmZlZJjmgzMwskxxQZmaWSXkFlKSpktZL+p2kbkkfllQjaaOkp5Kf0wpdrJmZVY58e1DfBX4eEe8E3gt0AzcAmyLiAmBTsm1mZjYmhgwoSWcBHwXWAkTEmxGxH7gaWJcctg64pjAlmplZJcqnBzUH2AP8QNKvJX1f0mRgRkTsSo55GZgx0IslLZG0RdKWPXv2jE3VFaKmpgZJw34Aw35NTU1Nyn9aM7NT5RNQ44H3Ad+LiLnAIfpdzovczIkDzp7oSS5Hbt++faedyHIsH/v27Uv7j2tmdop8AmonsDMiHkm215MLrFckzQRIfu4uTIlmZlaJhgyoiHgZ2CHpwqTpcuAJYAOwOGlbDNxTkArNzKwi5TsXXzNwh6QzgGeBL5ALtzuTCS+fBz5dmBLNzKwS5RVQEbEVmDfArsvHtBozM7OEZzPPsPj6W+Gms4r3XmZmGeKAyjB942DRlpaWRNxUlLcyM8uL5+IzM7NMckCZmVkmOaDMzCyTfA8q405MXVRo06Z5MnozyxYHVIaNdICEpKINrrD8SboN+ASwOyIakrb/Afwl8CbwDPCFZDJms4rnS3xmxXM7cGW/to1AQ0S8B/g34GvFLsosqxxQZkUSEQ8Ae/u13RsRvcnmL4FZRS/MLKMcUGbZ8R+Bf0m7CLOscECZZYCkFqAXuGOQ/V5XzSqOA8osZZI+T27wxGdjkNEtXlfNKpFH8ZmlSNKVwPXAn0bE62nXY5Yl7kGZFYmkDuBh4EJJO5Olav4OOBPYKGmrpPZUizTLEPegzIokIhoHaF5b9ELMSoR7UGZmlkkOKDMzyyQHlJmZZZIDyszMMskBZWZmmZTXKD5JPcCrwDGgNyLmSaoBfgLUAT3ApyNiX2HKNDOzSjOcHtSCiLg4IuYl2zcAmyLiAmBTsm1mZjYmRnOJ72pgXfJ8HXDNqKsxMzNL5BtQAdwr6VFJS5K2GRGxK3n+MjBjoBd6ksvCkDToI5/9ZmZZl+9MEvMj4kVJf0RuSpbf9d0ZESFp0EkugVsB5s2b52Vex0j/OUVPFzxeXdcqXU1NDfv2jewW+XA/1E2bNo29e/cOfaANKa+AiogXk5+7Jd0NfAB4RdLMiNglaSawu4B1Wp76hpF7S2Y5+/btK9oHNZ93Y2fIS3ySJks688Rz4M+A7cAGYHFy2GLgnkIVafnzpTwzKxf59KBmAHcn/+CNB/4xIn4u6VfAncmMzM8Dny5cmWZmVmmGDKiIeBZ47wDtfwAuL0RRZmZmnknCzMwyyetBlRkPkjCzcuGAKjMOJTMrF77EZ2ZmmeSAMjOzTHJAmZlZJjmgytAVV1yRdgk2AEm3SdotaXufthpJGyU9lfyclmaNZlnigCpDGzduTLsEG9jtwJX92rxsjdkgHFBmRRIRDwD9ZxH1sjVmg/Aw8zL0rW99i69+9atpl2H5yXvZGmAJQG1tbZFKKx/x9bfCTWcV771sTDigytAvfvGLtEuwEfCyNYWjbxws6mzmcVNR3qrs+RJfGfI9qJLySrJcDV62xuxUDqgyM27cOO677z7GjfP/2hLhZWvMBuF/xcrM8ePH2bp1K8ePH0+7FOtHUgfwMHChpJ3JUjU3A1dIegpYmGybGb4HVZY8QCKbIqJxkF1etsZsAO5BlZmqqiruv/9+qqqq0i7FzGxUHFBlJiLo7e0t2oglM7NC8SW+MnP8+HEWLlyYdhlmZqPmHlSZmTZtGtu2bWPaNE/pZmalzQFVZg4ePMjevXs5ePBg2qWYmY1K3gElqUrSryX9LNmeI+kRSU9L+omkMwpXpuXr2LFjXHbZZRw7diztUszMRmU4PagvA919tlcB34mI84F9QNNYFmYjU1dXx9NPP01dXV3apZiZjUpeASVpFvAXwPeTbQEfA9Ynh3gW5ow4cOAAr7/+OgcOHEi7FDOzUcl3FN8twPXAmcn224D9EdGbbO8Ezh3ohZ6Fubj27dvHe97znrTLMMuc3OfqwvMApbEzZA9K0ieA3RHx6EjeICJujYh5ETFv+vTpI/kVNgxXXXUVe/bs4aqrrkq7FLPMiIgRPUby2r17+y/5ZSOVTw/qUuAqSX8OTATeCnwXmCppfNKLmgW8WLgyLV/btm3jwIEDbNu2Le1SzMxGZcgeVER8LSJmRUQd8Blgc0R8FugEFiWHeRbmDJgwYQI9PT2cf/759PT0MGHChLRLMjMbsdF8D2oFsEzS0+TuSa0dm5JspMaPH8/mzZt588032bx5M+PHe6IQMytdw/oXLCLuB+5Pnj8LfGDsS7KRqK6u5vDhw9xyyy28+93v5pZbbuHw4cNUV1enXZqZ2Yj4I3aZOHr0KDU1NWzYsIETg1FqamrYv39/uoWZmY2QpzoqE1OnTmX//v2sXr2aQ4cOsXr1avbv38/UqVPTLs3MbEQcUGXi4MGDTJ06lblz5zJhwgTmzp3L1KlTPSefmZUsB1SZ6O3tZfXq1TQ3NzNx4kSam5tZvXo1vb29Q7/YzCyDHFBlorq6mr1797J9+3aOHTvG9u3b2bt3rwdJmFnJ8iCJMnHdddexYsUKAJYuXUp7ezsrVqxg6dKlKVdm+ZD0X4AvAgH8FvhCRLyRblVm6XJAlYm2tjYAbrzxRpYvX051dTVLly492W7ZJelc4D8D74qIw5LuJPel+NtTLcwsZQ6oMtLW1uZAKl3jgbdIOgpMAl5KuR6z1PkeVBnp6OigoaGBqqoqGhoa6OjoSLsky0NEvAh8C3gB2AUciIh7+x4jaYmkLZK27NmzJ40yzYrOAVUmOjo6aGlpoa2tjTfeeIO2tjZaWlocUiVA0jTgamAOcA4wWdLn+h7jVQGsEjmgykRraytr165lwYIFTJgwgQULFrB27VpaW1vTLs2GthB4LiL2RMRR4C7gkpRrMkudA6pMdHd3M3/+/FPa5s+fT3d3d0oV2TC8AHxI0qRkterLAf+Ps4rngCoT9fX1dHV1ndLW1dVFfX19ShVZviLiEWA98Bi5IebjgFtTLcosAxxQZaKlpYWmpiY6Ozs5evQonZ2dNDU10dLSknZploeI+HpEvDMiGiLi2og4knZNZmnzMPMy0djYCEBzczPd3d3U19fT2tp6st3MrNQ4oMpIY2OjA8nMyoYv8ZmZWSY5oMzMLJMcUGZmlkkOKDMzy6QhA0rSREn/Kuk3kh6X9I2kfY6kRyQ9Leknks4ofLlmZlYp8ulBHQE+FhHvBS4GrpT0IWAV8J2IOB/YBzQVrEozM6s4QwZU5LyWbE5IHgF8jNy33wHWAdcUokAzM6tMed2DklQlaSuwG9gIPAPsj4je5JCdwLmDvNbLBJiZ2bDlFVARcSwiLgZmAR8A3pnvG3iZADMzG4lhjeKLiP1AJ/BhYKqkEzNRzAJeHNvSzMyskuUzim+6pKnJ87cAV5BbCqATWJQcthi4p0A1mplZBcpnLr6ZwDpJVeQC7c6I+JmkJ4AfS/om8GtgbQHrNDOzCjNkQEXENmDuAO3PkrsfZWZmNuY8k4SZmWWSA8rMzDLJAWVmZpnkgDIzs0xyQJllgKSpktZL+p2kbkkfTrsms7R5yXezbPgu8POIWJSsDDAp7YLM0uaAMkuZpLOAjwKfB4iIN4E306zJLAt8ic8sfXOAPcAPJP1a0vclTe57gCddLhxJgz5Ot98KzwFllr7xwPuA70XEXOAQcEPfAzzpcuFExIgeVngOKLP07QR2RsQjyfZ6coFlVtEcUGYpi4iXgR2SLkyaLgeeSLEks0zwIAmzbGgG7khG8D0LfCHlesxS54Ayy4CI2ArMS7sOsyzxJT4zM8skB5SZmWWSA8rMzDLJAWVmZpnkgDIzs0xyQJmZWSZ5mLmZWT8DzbXn6Y2Kb8gelKTZkjolPSHpcUlfTtprJG2U9FTyc1rhyzUzK6zBJoL1BLHFl88lvl5geUS8C/gQ8NeS3kVuMstNEXEBsIl+k1uamZUyTwybviEDKiJ2RcRjyfNXgW7gXOBqYF1y2DrgmgLVaGZmFWhYgyQk1QFzgUeAGRGxK9n1MjBjkNd4HRszMxu2vANK0hTgp8BXIuJg332R6wMP2A/2OjZmVoq8OGH68gooSRPIhdMdEXFX0vyKpJnJ/pnA7sKUaGZWPIPdc/K9qOLLZxSfgLVAd0R8u8+uDcDi5Pli4J6xL8/MrPi8gm425PM9qEuBa4HfStqatN0I3AzcKakJeB74dEEqNDOzijRkQEVEFzDYRdjLx7YcMzOzHE91ZGZmmeSAMjOzTHJAmZlZJjmgzMwskxxQZhkhqUrSryX9LO1aKl1tbe0pX9Stra1Nu6SK5IAyy44vk5vr0lJUW1vLjh07uOSSS3jppZe45JJL2LFjh0MqBQ4oswyQNAv4C+D7addS6U6E04MPPsjMmTN58MEHT4aUFZcDyiwbbgGuB44PtNOTLhfX+vXrT7ttxeGAMkuZpE8AuyPi0cGO8aTLxbVo0aLTbltxOKDM0ncpcJWkHuDHwMck/SjdkirX7Nmzeeihh7j00kvZtWsXl156KQ899BCzZ89Ou7SKk89cfGZWQBHxNeBrAJIuA74aEZ9Ls6ZK9sILL1BbW8tDDz3EOeecA+RC64UXXki5ssrjgDIz68dhlA0OKLMMiYj7gftTLsMsE3wPyszMMskBZWZmmeSAMjOzTHJAmZlZJjmgzMwskxxQZmb9NDc3M3HiRCQxceJEmpub0y6pIjmgzMz6aG5upr29nZUrV3Lo0CFWrlxJe3u7QyoFQwaUpNsk7Za0vU9bjaSNkp5Kfk4rbJlmZsWxZs0aVq1axbJly5g0aRLLli1j1apVrFmzJu3SKk4+PajbgSv7td0AbIqIC4BNybaZWck7cuQIS5cuPaVt6dKlHDlyJKWKKteQARURDwB7+zVfDaxLnq8DrhnbsszM0lFdXU17e/spbe3t7VRXV6dUUeUa6VRHMyJiV/L8ZWDGYAdKWgIsAbwipZll3nXXXceKFSuAXM+pvb2dFStW/H+9Kiu8Uc/FFxEhKU6z/1bgVoB58+YNepyZWRa0tbUBcOONN7J8+XKqq6tZunTpyXYrnpEG1CuSZkbELkkzgd1jWZSZWZra2tocSBkw0mHmG4DFyfPFwD1jU46ZmVlOPsPMO4CHgQsl7ZTUBNwMXCHpKWBhsm1mZjZmhrzEFxGNg+y6fIxrMTMzO8kzSZiZWSY5oMzMLJMcUGZmlkkOKLOUSZotqVPSE5Iel/TltGsyy4JRf1HXzEatF1geEY9JOhN4VNLGiHgi7cLM0uQelFnKImJXRDyWPH8V6AbOTbcqs/Q5oMwyRFIdMBd4pF/7EklbJG3Zs2dPKrWZFZsDyiwjJE0Bfgp8JSIO9t0XEbdGxLyImDd9+vR0CjQrMgeUWQZImkAunO6IiLvSrscsCxxQZimTJGAt0B0R3067HrOscECZpe9S4FrgY5K2Jo8/T7sos7R5mLlZyiKiC1DadZhljXtQZmaWSQ4oMzPLJAeUmZllkgPKzMwyyQFlZmaZ5IAqIx0dHTQ0NFBVVUVDQwMdHR1pl2RWknwuZYOHmZeJjo4OWlpaWLt2LfPnz6erq4umpiYAGhsbU67OrHT4XMqQiCja4/3vf39YYVx00UWxefPmU9o2b94cF110UUoVlT9gSxTx/AmfR0Xhc6n4BjuXlNs3MpKuBL4LVAHfj4ibT3f8vHnzYsuWLSN+PxtcVVUVb7zxBhMmTDjZdvToUSZOnMixY8dSrKx8SXo0IuYV+319HhWWz6XiG+xcGvE9KElVwN8DHwfeBTRKetfIS7TRqK+vp6ur65S2rq4u6uvrU6rIrDT5XMqO0QyS+ADwdEQ8GxFvAj8Grh6bsmy4WlpaaGpqorOzk6NHj9LZ2UlTUxMtLS1pl2ZWUnwuZcdoBkmcC+zos70T+GD/gyQtAZYA1NbWjuLt7HRO3Lxtbm6mu7ub+vp6WltbfVPXbJh8LmXHiO9BSVoEXBkRX0y2rwU+GBF/M9hrfO3cyonvQZmNjTG/BwW8CMzusz0raTMzMxu10QTUr4ALJM2RdAbwGWDD2JRlZmaVbsT3oCKiV9LfAL8gN8z8toh4fMwqMzOzijaqmSQi4p+Bfx6jWszMzE7yXHxmZpZJDigzM8ukUU11NOw3k/YAzxftDSvX2cDv0y6iArw9IqYX+019HhWVz6XiGPBcKmpAWXFI2pLG93PMyo3PpXT5Ep+ZmWWSA8rMzDLJAVWebk27ALMy4XMpRb4HZWZmmeQelJmZZZIDyszMMskBVUYk3SZpt6TtaddiVqp8HmWHA6q83A5cmXYRZiXudnweZYIDqoxExAPA3rTrMCtlPo+ywwFlZmaZ5IAyM7NMckCZmVkmOaDMzCyTHFBlRFIH8DBwoaSdkprSrsms1Pg8yg5PdWRmZpnkHpSZmWWSA8rMzDLJAWVmZpnkgDIzs0xyQJmZWSY5oMzMLJMcUGZmlkn/D6MEYWk+J9BcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련데이터와 테스트데이터 나누기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9dc4556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 통계적 분석 필요\n",
    "text_max_len = 68 #50\n",
    "headlines_max_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "aa2c2a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6d4ca87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 96166\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55efb20",
   "metadata": {},
   "source": [
    "시작 토큰과 종료 토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5773e80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant an alumnus of upgrad and iiit pg p...</td>\n",
       "      <td>sostk upgrad learner switches to career in ml ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostk delhi techie wins free food from swiggy ...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india 12 matc...</td>\n",
       "      <td>new zealand defeated india by wickets in the f...</td>\n",
       "      <td>sostk new zealand end rohit sharma led india 1...</td>\n",
       "      <td>new zealand end rohit sharma led india 12 matc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india 12 matc...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant an alumnus of upgrad and iiit pg p...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india by wickets in the f...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostk upgrad learner switches to career in ml ...   \n",
       "1  sostk delhi techie wins free food from swiggy ...   \n",
       "2  sostk new zealand end rohit sharma led india 1...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india 12 matc...  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostk '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostk')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "df2853d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "70e0a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21182 21786 30831 ... 44257 31628 67212]\n",
      "테스트 데이터의 수 : 19233\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 분리\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "n_of_val = int(len(encoder_input)*0.2) #0.2%\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "72982c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 76933\n",
      "훈련 레이블의 개수 : 76933\n",
      "테스트 데이터의 개수 : 19233\n",
      "테스트 레이블의 개수 : 19233\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "275010a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩\n",
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6e595eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 73540\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 50395\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 23145\n",
      "단어 집합에서 희귀 단어의 비율: 68.52733206418276\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.299432750512202\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "757a5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하고자 합니다. \n",
    "# 위에서 이를 제외한 단어 집합의 크기를 8천여 개로 계산했는데, 이와 비슷한 값으로 어림잡아 단어 집합의 크기를 8,000으로 제한해볼게요. \n",
    "# 토크나이저를 정의할 때 num_words의 값을 정해주면, 단어 집합의 크기를 제한할 수 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "33758d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 22900#8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0bd53a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110, 1059, 253, 7, 9, 10, 16, 306, 20229, 12, 735, 1307, 2, 1421, 609, 44, 204, 10, 464, 13, 12, 3639, 114, 3, 16, 4170, 1059, 62, 9, 10, 20229, 8429, 2, 900, 62, 4170, 3, 709, 5, 7, 313, 1285, 1, 294, 3, 709, 10, 13, 1069, 2, 1793], [2408, 3, 79, 11, 5817, 4, 6849, 127, 22, 8324, 6, 7757, 3, 536, 79, 6, 137, 1, 235, 1679, 70, 524, 30, 54, 2712, 11, 805, 2, 1261, 19, 16, 222, 83, 290, 6, 3808, 1203, 58, 5, 44, 59, 325, 16, 11677, 15, 2237, 2926, 321, 410, 2, 1, 9986, 2, 4869, 1, 291], [1725, 340, 946, 4364, 337, 7, 163, 10, 1, 86, 21, 2029, 38, 1070, 75, 61, 3, 203, 6421, 8, 610, 5, 1560, 400, 1, 86, 7, 40, 1387, 2093, 8, 9328, 291, 19, 59, 185, 667, 2, 236, 8, 857, 242, 36, 400, 170, 2093, 21, 24, 1141, 8, 291, 488, 19, 1725, 3459, 2, 1, 185, 667]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "19f1937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6c0abd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 32585\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 22787\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9798\n",
      "단어 집합에서 희귀 단어의 비율: 69.93094982353844\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.815488095547318\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fd969ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 4106, 4, 6640, 432, 7, 138, 2617, 720], [1, 2525, 3165, 6, 4666, 66, 12, 5810, 7, 26, 4667], [1, 24, 994, 618, 50, 32, 4, 980, 4, 165, 846, 246], [1, 7928, 2096, 1104, 7, 2074, 1516, 5341, 4, 2668, 1974], [1, 794, 4817, 1788, 19, 1517, 72, 7, 1913, 93, 1037]]\n",
      "target\n",
      "decoder  [[4106, 4, 6640, 432, 7, 138, 2617, 720, 2], [2525, 3165, 6, 4666, 66, 12, 5810, 7, 26, 4667, 2], [24, 994, 618, 50, 32, 4, 980, 4, 165, 846, 246, 2], [7928, 2096, 1104, 7, 2074, 1516, 5341, 4, 2668, 1974, 2], [794, 4817, 1788, 19, 1517, 72, 7, 1913, 93, 1037, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 9700 #2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4247979a",
   "metadata": {},
   "source": [
    "패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fdd558b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3faa299",
   "metadata": {},
   "source": [
    "## Model    \n",
    "Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)      \n",
    "일반적인 seq2seq보다는 어텐션 메커니즘을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있어요.   \n",
    "실습 내용을 참고하여 어텐션 메커니즘을 사용한 seq2seq를 설계해 보세요.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "81abb2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d269f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, vocab_dim, hidden_size, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.embed = Embedding(vocab_size, vocab_dim)\n",
    "        self.lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=dropout)\n",
    "        self.lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=dropout)\n",
    "        self.lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=dropout)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        embed = self.embed(inputs)\n",
    "        out1, state_h1, state_c1 = self.lstm1(embed, training=training)\n",
    "        out2, state_h2, state_c2 = self.lstm2(out1, training=training)\n",
    "        out3, state_h3, state_c3 = self.lstm3(out2, training=training)\n",
    "\n",
    "        return out3, state_h3, state_c3\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=dropout)\n",
    "        self.attention = AdditiveAttention()\n",
    "        self.dense = Dense(vocab_size, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, enc_output, initial_state, training=False):\n",
    "        embedded = self.embedding(inputs)\n",
    "        lstm_out, h, c = self.lstm(embedded, initial_state=initial_state, training=training)\n",
    "        attn_output = self.attention([lstm_out, enc_output], training=training) # Pass encoder output\n",
    "        decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([lstm_out, attn_output])\n",
    "        outputs = self.dense(decoder_concat_input)\n",
    "        return outputs, h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf81cd9",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7aaf13a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.2.0-py3-none-any.whl (383 kB)\n",
      "     |████████████████████████████████| 383 kB 4.8 MB/s            \n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from optuna) (1.21.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from optuna) (4.62.3)\n",
      "Collecting sqlalchemy>=1.4.2\n",
      "  Downloading SQLAlchemy-2.0.38-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "     |████████████████████████████████| 3.1 MB 56.1 MB/s            \n",
      "\u001b[?25hCollecting alembic>=1.5.0\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "     |████████████████████████████████| 233 kB 73.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (4.0.1)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 12.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->optuna) (3.0.6)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.1.1-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (597 kB)\n",
      "     |████████████████████████████████| 597 kB 71.9 MB/s            \n",
      "\u001b[?25hCollecting typing-extensions>=4\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
      "Installing collected packages: typing-extensions, greenlet, sqlalchemy, Mako, colorlog, alembic, optuna\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.0.1\n",
      "    Uninstalling typing-extensions-4.0.1:\n",
      "      Successfully uninstalled typing-extensions-4.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.12.2 which is incompatible.\u001b[0m\n",
      "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 greenlet-3.1.1 optuna-4.2.0 sqlalchemy-2.0.38 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81eeb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, AdditiveAttention\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4129232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-07 07:17:23,948] A new study created in memory with name: no-name-483e4220-b8c5-4ad0-ac8e-02b0962e9ce6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "291/291 [==============================] - 20s 44ms/step - loss: 4.2405 - val_loss: 3.9608\n",
      "Epoch 2/50\n",
      "291/291 [==============================] - 12s 40ms/step - loss: 3.8234 - val_loss: 3.6469\n",
      "Epoch 3/50\n",
      "291/291 [==============================] - 12s 41ms/step - loss: 3.5753 - val_loss: 3.4934\n",
      "Epoch 4/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 3.4277 - val_loss: 3.3607\n",
      "Epoch 5/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 3.2937 - val_loss: 3.2476\n",
      "Epoch 6/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 3.1807 - val_loss: 3.1544\n",
      "Epoch 7/50\n",
      "291/291 [==============================] - 13s 43ms/step - loss: 3.0863 - val_loss: 3.0779\n",
      "Epoch 8/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 3.0069 - val_loss: 3.0232\n",
      "Epoch 9/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.9388 - val_loss: 2.9741\n",
      "Epoch 10/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.8792 - val_loss: 2.9312\n",
      "Epoch 11/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.8270 - val_loss: 2.8918\n",
      "Epoch 12/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.7806 - val_loss: 2.8618\n",
      "Epoch 13/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.7390 - val_loss: 2.8372\n",
      "Epoch 14/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.7008 - val_loss: 2.8162\n",
      "Epoch 15/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.6659 - val_loss: 2.7961\n",
      "Epoch 16/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.6333 - val_loss: 2.7678\n",
      "Epoch 17/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.6034 - val_loss: 2.7513\n",
      "Epoch 18/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.5759 - val_loss: 2.7424\n",
      "Epoch 19/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.5490 - val_loss: 2.7220\n",
      "Epoch 20/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.5248 - val_loss: 2.7096\n",
      "Epoch 21/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.5017 - val_loss: 2.7002\n",
      "Epoch 22/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.4796 - val_loss: 2.6888\n",
      "Epoch 23/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.4602 - val_loss: 2.6765\n",
      "Epoch 24/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.4401 - val_loss: 2.6676\n",
      "Epoch 25/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.4220 - val_loss: 2.6610\n",
      "Epoch 26/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.4037 - val_loss: 2.6512\n",
      "Epoch 27/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.3872 - val_loss: 2.6480\n",
      "Epoch 28/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.3714 - val_loss: 2.6400\n",
      "Epoch 29/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.3566 - val_loss: 2.6411\n",
      "Epoch 30/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.3423 - val_loss: 2.6296\n",
      "Epoch 31/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.3279 - val_loss: 2.6244\n",
      "Epoch 32/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.3143 - val_loss: 2.6228\n",
      "Epoch 33/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.3015 - val_loss: 2.6168\n",
      "Epoch 34/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2881 - val_loss: 2.6163\n",
      "Epoch 35/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2760 - val_loss: 2.6100\n",
      "Epoch 36/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2656 - val_loss: 2.6071\n",
      "Epoch 37/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2526 - val_loss: 2.6031\n",
      "Epoch 38/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2431 - val_loss: 2.5991\n",
      "Epoch 39/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2327 - val_loss: 2.5955\n",
      "Epoch 40/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2220 - val_loss: 2.5941\n",
      "Epoch 41/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2134 - val_loss: 2.5959\n",
      "Epoch 42/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2024 - val_loss: 2.5875\n",
      "Epoch 43/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.1944 - val_loss: 2.5875\n",
      "Epoch 44/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.1836 - val_loss: 2.5910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-07 07:26:34,847] Trial 0 finished with value: 2.587514877319336 and parameters: {'embed_dim': 71, 'hidden_size': 147, 'optimizer': 'rmsprop'}. Best is trial 0 with value: 2.587514877319336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00044: early stopping\n",
      "Epoch 1/50\n",
      "291/291 [==============================] - 20s 52ms/step - loss: 4.2175 - val_loss: 3.9166\n",
      "Epoch 2/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 3.7994 - val_loss: 3.6250\n",
      "Epoch 3/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 3.5524 - val_loss: 3.4595\n",
      "Epoch 4/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 3.3830 - val_loss: 3.3144\n",
      "Epoch 5/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 3.2394 - val_loss: 3.2010\n",
      "Epoch 6/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 3.1248 - val_loss: 3.1127\n",
      "Epoch 7/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 3.0325 - val_loss: 3.0410\n",
      "Epoch 8/50\n",
      "291/291 [==============================] - 14s 50ms/step - loss: 2.9540 - val_loss: 2.9799\n",
      "Epoch 9/50\n",
      "291/291 [==============================] - 14s 50ms/step - loss: 2.8869 - val_loss: 2.9301\n",
      "Epoch 10/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.8281 - val_loss: 2.8895\n",
      "Epoch 11/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.7736 - val_loss: 2.8545\n",
      "Epoch 12/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.7254 - val_loss: 2.8215\n",
      "Epoch 13/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.6814 - val_loss: 2.7928\n",
      "Epoch 14/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.6409 - val_loss: 2.7723\n",
      "Epoch 15/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.6044 - val_loss: 2.7455\n",
      "Epoch 16/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.5701 - val_loss: 2.7286\n",
      "Epoch 17/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.5394 - val_loss: 2.7135\n",
      "Epoch 18/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.5100 - val_loss: 2.7015\n",
      "Epoch 19/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.4835 - val_loss: 2.6877\n",
      "Epoch 20/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.4579 - val_loss: 2.6739\n",
      "Epoch 21/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.4336 - val_loss: 2.6599\n",
      "Epoch 22/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.4114 - val_loss: 2.6522\n",
      "Epoch 23/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.3894 - val_loss: 2.6454\n",
      "Epoch 24/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.3705 - val_loss: 2.6368\n",
      "Epoch 25/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.3507 - val_loss: 2.6298\n",
      "Epoch 26/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.3334 - val_loss: 2.6243\n",
      "Epoch 27/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.3153 - val_loss: 2.6221\n",
      "Epoch 28/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.2985 - val_loss: 2.6144\n",
      "Epoch 29/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.2834 - val_loss: 2.6095\n",
      "Epoch 30/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.2679 - val_loss: 2.6082\n",
      "Epoch 31/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.2535 - val_loss: 2.6036\n",
      "Epoch 32/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.2397 - val_loss: 2.5985\n",
      "Epoch 33/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.2246 - val_loss: 2.5956\n",
      "Epoch 34/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.2127 - val_loss: 2.5902\n",
      "Epoch 35/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.2010 - val_loss: 2.5868\n",
      "Epoch 36/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.1885 - val_loss: 2.5911\n",
      "Epoch 37/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.1765 - val_loss: 2.5832\n",
      "Epoch 38/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.1655 - val_loss: 2.5820\n",
      "Epoch 39/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.1540 - val_loss: 2.5820\n",
      "Epoch 40/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.1438 - val_loss: 2.5797\n",
      "Epoch 41/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.1335 - val_loss: 2.5800\n",
      "Epoch 42/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.1255 - val_loss: 2.5764\n",
      "Epoch 43/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.1144 - val_loss: 2.5728\n",
      "Epoch 44/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.1068 - val_loss: 2.5778\n",
      "Epoch 45/50\n",
      "291/291 [==============================] - 14s 49ms/step - loss: 2.0961 - val_loss: 2.5794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-07 07:37:23,176] Trial 1 finished with value: 2.57277250289917 and parameters: {'embed_dim': 72, 'hidden_size': 165, 'optimizer': 'rmsprop'}. Best is trial 1 with value: 2.57277250289917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00045: early stopping\n",
      "Epoch 1/50\n",
      "291/291 [==============================] - 22s 59ms/step - loss: 4.2090 - val_loss: 3.9179\n",
      "Epoch 2/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 3.7751 - val_loss: 3.5944\n",
      "Epoch 3/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 3.5136 - val_loss: 3.4205\n",
      "Epoch 4/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 3.3362 - val_loss: 3.2653\n",
      "Epoch 5/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 3.1948 - val_loss: 3.1591\n",
      "Epoch 6/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 3.0797 - val_loss: 3.0613\n",
      "Epoch 7/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.9824 - val_loss: 3.0035\n",
      "Epoch 8/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.8997 - val_loss: 2.9337\n",
      "Epoch 9/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.8287 - val_loss: 2.8842\n",
      "Epoch 10/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.7670 - val_loss: 2.8479\n",
      "Epoch 11/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.7103 - val_loss: 2.8071\n",
      "Epoch 12/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.6606 - val_loss: 2.7767\n",
      "Epoch 13/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.6158 - val_loss: 2.7520\n",
      "Epoch 14/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.5746 - val_loss: 2.7290\n",
      "Epoch 15/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.5375 - val_loss: 2.7089\n",
      "Epoch 16/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.5025 - val_loss: 2.6903\n",
      "Epoch 17/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.4686 - val_loss: 2.6764\n",
      "Epoch 18/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.4388 - val_loss: 2.6682\n",
      "Epoch 19/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.4102 - val_loss: 2.6549\n",
      "Epoch 20/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.3842 - val_loss: 2.6443\n",
      "Epoch 21/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.3597 - val_loss: 2.6337\n",
      "Epoch 22/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.3357 - val_loss: 2.6207\n",
      "Epoch 23/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.3130 - val_loss: 2.6217\n",
      "Epoch 24/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.2922 - val_loss: 2.6142\n",
      "Epoch 25/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.2718 - val_loss: 2.6050\n",
      "Epoch 26/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.2528 - val_loss: 2.6030\n",
      "Epoch 27/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.2344 - val_loss: 2.5978\n",
      "Epoch 28/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.2180 - val_loss: 2.5963\n",
      "Epoch 29/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.1998 - val_loss: 2.5921\n",
      "Epoch 30/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.1834 - val_loss: 2.5899\n",
      "Epoch 31/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.1697 - val_loss: 2.5878\n",
      "Epoch 32/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.1552 - val_loss: 2.5848\n",
      "Epoch 33/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.1393 - val_loss: 2.5827\n",
      "Epoch 34/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.1263 - val_loss: 2.5805\n",
      "Epoch 35/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.1136 - val_loss: 2.5820\n",
      "Epoch 36/50\n",
      "291/291 [==============================] - 16s 56ms/step - loss: 2.1009 - val_loss: 2.5822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-07 07:47:17,501] Trial 2 finished with value: 2.5804829597473145 and parameters: {'embed_dim': 77, 'hidden_size': 188, 'optimizer': 'rmsprop'}. Best is trial 1 with value: 2.57277250289917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00036: early stopping\n",
      "Epoch 1/50\n",
      "291/291 [==============================] - 18s 47ms/step - loss: 4.2368 - val_loss: 3.9513\n",
      "Epoch 2/50\n",
      "291/291 [==============================] - 13s 43ms/step - loss: 3.8262 - val_loss: 3.6637\n",
      "Epoch 3/50\n",
      "291/291 [==============================] - 13s 43ms/step - loss: 3.5746 - val_loss: 3.4767\n",
      "Epoch 4/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 3.3999 - val_loss: 3.3300\n",
      "Epoch 5/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 3.2624 - val_loss: 3.2243\n",
      "Epoch 6/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 3.1539 - val_loss: 3.1346\n",
      "Epoch 7/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 3.0661 - val_loss: 3.0697\n",
      "Epoch 8/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.9894 - val_loss: 3.0161\n",
      "Epoch 9/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.9204 - val_loss: 2.9554\n",
      "Epoch 10/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.8605 - val_loss: 2.9145\n",
      "Epoch 11/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.8063 - val_loss: 2.8793\n",
      "Epoch 12/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.7580 - val_loss: 2.8439\n",
      "Epoch 13/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.7136 - val_loss: 2.8180\n",
      "Epoch 14/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.6739 - val_loss: 2.7949\n",
      "Epoch 15/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.6373 - val_loss: 2.7642\n",
      "Epoch 16/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.6037 - val_loss: 2.7490\n",
      "Epoch 17/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.5727 - val_loss: 2.7288\n",
      "Epoch 18/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.5431 - val_loss: 2.7147\n",
      "Epoch 19/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.5150 - val_loss: 2.6953\n",
      "Epoch 20/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.4897 - val_loss: 2.6891\n",
      "Epoch 21/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.4665 - val_loss: 2.6731\n",
      "Epoch 22/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.4447 - val_loss: 2.6641\n",
      "Epoch 23/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.4232 - val_loss: 2.6533\n",
      "Epoch 24/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.4037 - val_loss: 2.6447\n",
      "Epoch 25/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.3841 - val_loss: 2.6345\n",
      "Epoch 26/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.3667 - val_loss: 2.6328\n",
      "Epoch 27/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.3495 - val_loss: 2.6211\n",
      "Epoch 28/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.3330 - val_loss: 2.6154\n",
      "Epoch 29/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.3183 - val_loss: 2.6162\n",
      "Epoch 30/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.3024 - val_loss: 2.6037\n",
      "Epoch 31/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.2892 - val_loss: 2.5998\n",
      "Epoch 32/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2749 - val_loss: 2.5943\n",
      "Epoch 33/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2619 - val_loss: 2.5948\n",
      "Epoch 34/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.2493 - val_loss: 2.5901\n",
      "Epoch 35/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2371 - val_loss: 2.5868\n",
      "Epoch 36/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2262 - val_loss: 2.5872\n",
      "Epoch 37/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.2137 - val_loss: 2.5789\n",
      "Epoch 38/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.2036 - val_loss: 2.5768\n",
      "Epoch 39/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.1928 - val_loss: 2.5763\n",
      "Epoch 40/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.1818 - val_loss: 2.5758\n",
      "Epoch 41/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.1725 - val_loss: 2.5734\n",
      "Epoch 42/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.1641 - val_loss: 2.5698\n",
      "Epoch 43/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.1538 - val_loss: 2.5651\n",
      "Epoch 44/50\n",
      "291/291 [==============================] - 12s 42ms/step - loss: 2.1445 - val_loss: 2.5667\n",
      "Epoch 45/50\n",
      "291/291 [==============================] - 12s 43ms/step - loss: 2.1371 - val_loss: 2.5654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-07 07:57:14,323] Trial 3 finished with value: 2.5650789737701416 and parameters: {'embed_dim': 81, 'hidden_size': 145, 'optimizer': 'rmsprop'}. Best is trial 3 with value: 2.5650789737701416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00045: early stopping\n",
      "Epoch 1/50\n",
      "291/291 [==============================] - 27s 76ms/step - loss: 4.1710 - val_loss: 3.8492\n",
      "Epoch 2/50\n",
      "291/291 [==============================] - 21s 73ms/step - loss: 3.6907 - val_loss: 3.5456\n",
      "Epoch 3/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 3.4281 - val_loss: 3.3246\n",
      "Epoch 4/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 3.2337 - val_loss: 3.1775\n",
      "Epoch 5/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 3.0814 - val_loss: 3.0613\n",
      "Epoch 6/50\n",
      "291/291 [==============================] - 21s 73ms/step - loss: 2.9610 - val_loss: 2.9742\n",
      "Epoch 7/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.8611 - val_loss: 2.9047\n",
      "Epoch 8/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.7753 - val_loss: 2.8462\n",
      "Epoch 9/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.6990 - val_loss: 2.7961\n",
      "Epoch 10/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.6325 - val_loss: 2.7588\n",
      "Epoch 11/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.5726 - val_loss: 2.7260\n",
      "Epoch 12/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.5190 - val_loss: 2.6980\n",
      "Epoch 13/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.4696 - val_loss: 2.6744\n",
      "Epoch 14/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.4237 - val_loss: 2.6558\n",
      "Epoch 15/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.3825 - val_loss: 2.6333\n",
      "Epoch 16/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.3432 - val_loss: 2.6234\n",
      "Epoch 17/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.3074 - val_loss: 2.6119\n",
      "Epoch 18/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.2729 - val_loss: 2.6006\n",
      "Epoch 19/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.2415 - val_loss: 2.5942\n",
      "Epoch 20/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.2111 - val_loss: 2.5893\n",
      "Epoch 21/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.1837 - val_loss: 2.5823\n",
      "Epoch 22/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.1585 - val_loss: 2.5802\n",
      "Epoch 23/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.1327 - val_loss: 2.5808\n",
      "Epoch 24/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.1086 - val_loss: 2.5798\n",
      "Epoch 25/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.0869 - val_loss: 2.5746\n",
      "Epoch 26/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.0666 - val_loss: 2.5698\n",
      "Epoch 27/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.0453 - val_loss: 2.5715\n",
      "Epoch 28/50\n",
      "291/291 [==============================] - 21s 72ms/step - loss: 2.0259 - val_loss: 2.5757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-07 08:07:13,899] Trial 4 finished with value: 2.569812297821045 and parameters: {'embed_dim': 103, 'hidden_size': 234, 'optimizer': 'rmsprop'}. Best is trial 3 with value: 2.5650789737701416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00028: early stopping\n",
      "Epoch 1/50\n",
      "291/291 [==============================] - 25s 67ms/step - loss: 4.1800 - val_loss: 3.8674\n",
      "Epoch 2/50\n",
      "291/291 [==============================] - 19s 65ms/step - loss: 3.7075 - val_loss: 3.5228\n",
      "Epoch 3/50\n",
      "291/291 [==============================] - 19s 64ms/step - loss: 3.4368 - val_loss: 3.3499\n",
      "Epoch 4/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 3.2552 - val_loss: 3.1908\n",
      "Epoch 5/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 3.1095 - val_loss: 3.0841\n",
      "Epoch 6/50\n",
      "291/291 [==============================] - 19s 64ms/step - loss: 2.9933 - val_loss: 3.0008\n",
      "Epoch 7/50\n",
      "291/291 [==============================] - 18s 64ms/step - loss: 2.8983 - val_loss: 2.9339\n",
      "Epoch 8/50\n",
      "291/291 [==============================] - 18s 64ms/step - loss: 2.8168 - val_loss: 2.8730\n",
      "Epoch 9/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.7451 - val_loss: 2.8281\n",
      "Epoch 10/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.6825 - val_loss: 2.7877\n",
      "Epoch 11/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.6249 - val_loss: 2.7560\n",
      "Epoch 12/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.5732 - val_loss: 2.7270\n",
      "Epoch 13/50\n",
      "291/291 [==============================] - 19s 64ms/step - loss: 2.5256 - val_loss: 2.6976\n",
      "Epoch 14/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.4815 - val_loss: 2.6796\n",
      "Epoch 15/50\n",
      "291/291 [==============================] - 18s 64ms/step - loss: 2.4425 - val_loss: 2.6581\n",
      "Epoch 16/50\n",
      "291/291 [==============================] - 19s 64ms/step - loss: 2.4052 - val_loss: 2.6412\n",
      "Epoch 17/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.3711 - val_loss: 2.6291\n",
      "Epoch 18/50\n",
      "291/291 [==============================] - 18s 64ms/step - loss: 2.3387 - val_loss: 2.6130\n",
      "Epoch 19/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.3087 - val_loss: 2.6067\n",
      "Epoch 20/50\n",
      "291/291 [==============================] - 18s 64ms/step - loss: 2.2795 - val_loss: 2.5958\n",
      "Epoch 21/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.2534 - val_loss: 2.5914\n",
      "Epoch 22/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.2269 - val_loss: 2.5809\n",
      "Epoch 23/50\n",
      "291/291 [==============================] - 19s 64ms/step - loss: 2.2043 - val_loss: 2.5775\n",
      "Epoch 24/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.1807 - val_loss: 2.5731\n",
      "Epoch 25/50\n",
      "291/291 [==============================] - 18s 64ms/step - loss: 2.1600 - val_loss: 2.5689\n",
      "Epoch 26/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.1383 - val_loss: 2.5656\n",
      "Epoch 27/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.1193 - val_loss: 2.5640\n",
      "Epoch 28/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.1021 - val_loss: 2.5632\n",
      "Epoch 29/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.0826 - val_loss: 2.5661\n",
      "Epoch 30/50\n",
      "291/291 [==============================] - 18s 64ms/step - loss: 2.0657 - val_loss: 2.5614\n",
      "Epoch 31/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.0494 - val_loss: 2.5569\n",
      "Epoch 32/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.0332 - val_loss: 2.5630\n",
      "Epoch 33/50\n",
      "291/291 [==============================] - 18s 63ms/step - loss: 2.0196 - val_loss: 2.5590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-07 08:18:03,116] Trial 5 finished with value: 2.5569112300872803 and parameters: {'embed_dim': 120, 'hidden_size': 197, 'optimizer': 'rmsprop'}. Best is trial 5 with value: 2.5569112300872803.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00033: early stopping\n",
      "Epoch 1/50\n",
      "291/291 [==============================] - 26s 73ms/step - loss: 4.2904 - val_loss: 4.0192\n",
      "Epoch 2/50\n",
      "291/291 [==============================] - 21s 71ms/step - loss: 3.9742 - val_loss: 3.8732\n",
      "Epoch 3/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 3.7854 - val_loss: 3.6674\n",
      "Epoch 4/50\n",
      "291/291 [==============================] - 20s 69ms/step - loss: 3.5958 - val_loss: 3.4799\n",
      "Epoch 5/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 3.4161 - val_loss: 3.3207\n",
      "Epoch 6/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 3.2397 - val_loss: 3.1750\n",
      "Epoch 7/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 3.0827 - val_loss: 3.0441\n",
      "Epoch 8/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.9472 - val_loss: 2.9381\n",
      "Epoch 9/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.8300 - val_loss: 2.8611\n",
      "Epoch 10/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.7310 - val_loss: 2.7910\n",
      "Epoch 11/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.6423 - val_loss: 2.7397\n",
      "Epoch 12/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.5661 - val_loss: 2.6917\n",
      "Epoch 13/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.4988 - val_loss: 2.6597\n",
      "Epoch 14/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.4385 - val_loss: 2.6292\n",
      "Epoch 15/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.3837 - val_loss: 2.6083\n",
      "Epoch 16/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.3339 - val_loss: 2.5903\n",
      "Epoch 17/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.2888 - val_loss: 2.5782\n",
      "Epoch 18/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.2478 - val_loss: 2.5633\n",
      "Epoch 19/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.2088 - val_loss: 2.5560\n",
      "Epoch 20/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.1732 - val_loss: 2.5471\n",
      "Epoch 21/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.1396 - val_loss: 2.5434\n",
      "Epoch 22/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.1073 - val_loss: 2.5349\n",
      "Epoch 23/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.0770 - val_loss: 2.5337\n",
      "Epoch 24/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.0493 - val_loss: 2.5343\n",
      "Epoch 25/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 2.0223 - val_loss: 2.5329\n",
      "Epoch 26/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 1.9969 - val_loss: 2.5320\n",
      "Epoch 27/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 1.9724 - val_loss: 2.5318\n",
      "Epoch 28/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 1.9495 - val_loss: 2.5328\n",
      "Epoch 29/50\n",
      "291/291 [==============================] - 20s 70ms/step - loss: 1.9285 - val_loss: 2.5379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-07 08:28:10,847] Trial 6 finished with value: 2.5317976474761963 and parameters: {'embed_dim': 121, 'hidden_size': 232, 'optimizer': 'adam'}. Best is trial 6 with value: 2.5317976474761963.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00029: early stopping\n",
      "Epoch 1/50\n",
      "291/291 [==============================] - 26s 70ms/step - loss: 4.3094 - val_loss: 4.0413\n",
      "Epoch 2/50\n",
      "291/291 [==============================] - 20s 68ms/step - loss: 3.9837 - val_loss: 3.8564\n",
      "Epoch 3/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 3.7666 - val_loss: 3.6409\n",
      "Epoch 4/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 3.5435 - val_loss: 3.3932\n",
      "Epoch 5/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 3.2928 - val_loss: 3.1898\n",
      "Epoch 6/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 3.1033 - val_loss: 3.0395\n",
      "Epoch 7/50\n",
      "291/291 [==============================] - 20s 68ms/step - loss: 2.9534 - val_loss: 2.9326\n",
      "Epoch 8/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.8351 - val_loss: 2.8526\n",
      "Epoch 9/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.7386 - val_loss: 2.7854\n",
      "Epoch 10/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.6564 - val_loss: 2.7383\n",
      "Epoch 11/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.5844 - val_loss: 2.6960\n",
      "Epoch 12/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.5205 - val_loss: 2.6607\n",
      "Epoch 13/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.4642 - val_loss: 2.6295\n",
      "Epoch 14/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.4144 - val_loss: 2.6043\n",
      "Epoch 15/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.3675 - val_loss: 2.5864\n",
      "Epoch 16/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.3249 - val_loss: 2.5707\n",
      "Epoch 17/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.2855 - val_loss: 2.5567\n",
      "Epoch 18/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.2492 - val_loss: 2.5473\n",
      "Epoch 19/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.2152 - val_loss: 2.5363\n",
      "Epoch 20/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.1849 - val_loss: 2.5297\n",
      "Epoch 21/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.1537 - val_loss: 2.5204\n",
      "Epoch 22/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.1260 - val_loss: 2.5179\n",
      "Epoch 23/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.0984 - val_loss: 2.5136\n",
      "Epoch 24/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.0738 - val_loss: 2.5116\n",
      "Epoch 25/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.0502 - val_loss: 2.5096\n",
      "Epoch 26/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.0267 - val_loss: 2.5077\n",
      "Epoch 27/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 2.0050 - val_loss: 2.5047\n",
      "Epoch 28/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 1.9854 - val_loss: 2.5077\n",
      "Epoch 29/50\n",
      "291/291 [==============================] - 20s 67ms/step - loss: 1.9631 - val_loss: 2.5051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-07 08:37:45,406] Trial 7 finished with value: 2.504713535308838 and parameters: {'embed_dim': 107, 'hidden_size': 215, 'optimizer': 'adam'}. Best is trial 7 with value: 2.504713535308838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00029: early stopping\n",
      "Epoch 1/50\n",
      "291/291 [==============================] - 29s 81ms/step - loss: 4.1861 - val_loss: 3.9094\n",
      "Epoch 2/50\n",
      "291/291 [==============================] - 23s 78ms/step - loss: 3.7416 - val_loss: 3.5540\n",
      "Epoch 3/50\n",
      "291/291 [==============================] - 22s 77ms/step - loss: 3.4467 - val_loss: 3.3439\n",
      "Epoch 4/50\n",
      "291/291 [==============================] - 22s 77ms/step - loss: 3.2408 - val_loss: 3.1803\n",
      "Epoch 5/50\n",
      "291/291 [==============================] - 23s 77ms/step - loss: 3.0905 - val_loss: 3.0660\n",
      "Epoch 6/50\n",
      "291/291 [==============================] - 23s 78ms/step - loss: 2.9679 - val_loss: 2.9822\n",
      "Epoch 7/50\n",
      "291/291 [==============================] - 23s 77ms/step - loss: 2.8662 - val_loss: 2.9015\n",
      "Epoch 8/50\n",
      "291/291 [==============================] - 22s 77ms/step - loss: 2.7793 - val_loss: 2.8438\n",
      "Epoch 9/50\n",
      "291/291 [==============================] - 22s 77ms/step - loss: 2.7025 - val_loss: 2.8005\n",
      "Epoch 10/50\n",
      "291/291 [==============================] - 23s 78ms/step - loss: 2.6352 - val_loss: 2.7615\n",
      "Epoch 11/50\n",
      "291/291 [==============================] - 23s 78ms/step - loss: 2.5744 - val_loss: 2.7325\n",
      "Epoch 12/50\n",
      "291/291 [==============================] - 23s 78ms/step - loss: 2.5204 - val_loss: 2.7010\n",
      "Epoch 13/50\n",
      "291/291 [==============================] - 23s 77ms/step - loss: 2.4697 - val_loss: 2.6858\n",
      "Epoch 14/50\n",
      "291/291 [==============================] - 23s 77ms/step - loss: 2.4245 - val_loss: 2.6601\n",
      "Epoch 15/50\n",
      "291/291 [==============================] - 22s 77ms/step - loss: 2.3822 - val_loss: 2.6476\n",
      "Epoch 16/50\n",
      "291/291 [==============================] - 22s 77ms/step - loss: 2.3431 - val_loss: 2.6333\n",
      "Epoch 17/50\n",
      "291/291 [==============================] - 22s 77ms/step - loss: 2.3068 - val_loss: 2.6227\n",
      "Epoch 18/50\n",
      "291/291 [==============================] - 23s 78ms/step - loss: 2.2717 - val_loss: 2.6208\n",
      "Epoch 19/50\n",
      "291/291 [==============================] - 23s 77ms/step - loss: 2.2398 - val_loss: 2.6058\n",
      "Epoch 20/50\n",
      "291/291 [==============================] - 23s 77ms/step - loss: 2.2103 - val_loss: 2.6058\n",
      "Epoch 21/50\n",
      "291/291 [==============================] - 23s 77ms/step - loss: 2.1814 - val_loss: 2.6025\n",
      "Epoch 22/50\n",
      "291/291 [==============================] - 23s 77ms/step - loss: 2.1550 - val_loss: 2.5951\n",
      "Epoch 23/50\n",
      "291/291 [==============================] - 23s 77ms/step - loss: 2.1279 - val_loss: 2.5948\n",
      "Epoch 24/50\n",
      "291/291 [==============================] - 23s 77ms/step - loss: 2.1033 - val_loss: 2.5933\n",
      "Epoch 25/50\n",
      "291/291 [==============================] - 22s 77ms/step - loss: 2.0809 - val_loss: 2.5904\n",
      "Epoch 26/50\n",
      "291/291 [==============================] - 23s 77ms/step - loss: 2.0597 - val_loss: 2.5950\n",
      "Epoch 27/50\n",
      "291/291 [==============================] - 22s 77ms/step - loss: 2.0356 - val_loss: 2.5940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-07 08:48:00,687] Trial 8 finished with value: 2.590369939804077 and parameters: {'embed_dim': 86, 'hidden_size': 255, 'optimizer': 'rmsprop'}. Best is trial 7 with value: 2.504713535308838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00027: early stopping\n",
      "Epoch 1/50\n",
      "291/291 [==============================] - 19s 49ms/step - loss: 4.3643 - val_loss: 4.0682\n",
      "Epoch 2/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 3.9998 - val_loss: 3.8597\n",
      "Epoch 3/50\n",
      "291/291 [==============================] - 13s 46ms/step - loss: 3.7421 - val_loss: 3.5610\n",
      "Epoch 4/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 3.4633 - val_loss: 3.3472\n",
      "Epoch 5/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 3.2694 - val_loss: 3.1987\n",
      "Epoch 6/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 3.1349 - val_loss: 3.0912\n",
      "Epoch 7/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 3.0246 - val_loss: 3.0041\n",
      "Epoch 8/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.9325 - val_loss: 2.9388\n",
      "Epoch 9/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.8532 - val_loss: 2.8842\n",
      "Epoch 10/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.7860 - val_loss: 2.8343\n",
      "Epoch 11/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.7260 - val_loss: 2.7956\n",
      "Epoch 12/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.6731 - val_loss: 2.7605\n",
      "Epoch 13/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.6257 - val_loss: 2.7315\n",
      "Epoch 14/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.5830 - val_loss: 2.7042\n",
      "Epoch 15/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.5446 - val_loss: 2.6818\n",
      "Epoch 16/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.5086 - val_loss: 2.6628\n",
      "Epoch 17/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.4760 - val_loss: 2.6447\n",
      "Epoch 18/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.4449 - val_loss: 2.6291\n",
      "Epoch 19/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.4175 - val_loss: 2.6130\n",
      "Epoch 20/50\n",
      "291/291 [==============================] - 13s 46ms/step - loss: 2.3903 - val_loss: 2.5999\n",
      "Epoch 21/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.3658 - val_loss: 2.5913\n",
      "Epoch 22/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.3420 - val_loss: 2.5805\n",
      "Epoch 23/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.3188 - val_loss: 2.5701\n",
      "Epoch 24/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.2987 - val_loss: 2.5637\n",
      "Epoch 25/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.2789 - val_loss: 2.5590\n",
      "Epoch 26/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.2605 - val_loss: 2.5525\n",
      "Epoch 27/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.2402 - val_loss: 2.5449\n",
      "Epoch 28/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.2249 - val_loss: 2.5403\n",
      "Epoch 29/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.2091 - val_loss: 2.5373\n",
      "Epoch 30/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.1934 - val_loss: 2.5304\n",
      "Epoch 31/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.1763 - val_loss: 2.5270\n",
      "Epoch 32/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.1622 - val_loss: 2.5256\n",
      "Epoch 33/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.1489 - val_loss: 2.5217\n",
      "Epoch 34/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.1362 - val_loss: 2.5188\n",
      "Epoch 35/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.1221 - val_loss: 2.5161\n",
      "Epoch 36/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.1097 - val_loss: 2.5146\n",
      "Epoch 37/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.0959 - val_loss: 2.5127\n",
      "Epoch 38/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.0852 - val_loss: 2.5126\n",
      "Epoch 39/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.0753 - val_loss: 2.5100\n",
      "Epoch 40/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.0642 - val_loss: 2.5084\n",
      "Epoch 41/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.0536 - val_loss: 2.5095\n",
      "Epoch 42/50\n",
      "291/291 [==============================] - 13s 45ms/step - loss: 2.0432 - val_loss: 2.5088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-07 08:57:20,897] Trial 9 finished with value: 2.50839900970459 and parameters: {'embed_dim': 76, 'hidden_size': 157, 'optimizer': 'adam'}. Best is trial 7 with value: 2.504713535308838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00042: early stopping\n"
     ]
    }
   ],
   "source": [
    "def create_model(trial):\n",
    "    embed_dim = trial.suggest_int('embed_dim', 64, 128)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 128, 256)\n",
    "\n",
    "    # Encoder\n",
    "    enc_inputs = Input(shape=(text_max_len,))\n",
    "    encoder = Encoder(src_vocab, embed_dim, hidden_size, dropout=0.4)\n",
    "\n",
    "    enc_output, state_h, state_c = encoder(enc_inputs)\n",
    "\n",
    "    # Decoder\n",
    "    dec_inputs = Input(shape=(None,))\n",
    "    decoder = Decoder(tar_vocab, embed_dim, hidden_size, dropout=0.4)\n",
    "\n",
    "    dec_outputs, _, _ = decoder(dec_inputs, enc_output, initial_state=[state_h, state_c])\n",
    "\n",
    "    model = Model([enc_inputs, dec_inputs], dec_outputs)\n",
    "\n",
    "    optimizer = trial.suggest_categorical('optimizer', ['rmsprop', 'adam'])\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "    history = model.fit(\n",
    "        x=[encoder_input_train, decoder_input_train],\n",
    "        y=decoder_target_train,\n",
    "        validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "        batch_size=256,\n",
    "        callbacks=[es],\n",
    "        epochs=50,\n",
    "        verbose=1  \n",
    "    )\n",
    "\n",
    "    # Get best validation loss \n",
    "    best_val_loss = min(history.history['val_loss'])\n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')  \n",
    "study.optimize(objective, n_trials=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ab4a662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Params: {'embed_dim': 107, 'hidden_size': 215, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# number of trials를 충분히 설정후 학습후 확인 가능(시간제약 이슈로 생략)\n",
    "trial = study.best_trial\n",
    "print(f'  Params: {trial.params}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeb0904",
   "metadata": {},
   "source": [
    "### Train with Best Hyper Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "717f44dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "301/301 [==============================] - 40s 116ms/step - loss: 5.9142 - val_loss: 5.5187\n",
      "Epoch 2/50\n",
      "301/301 [==============================] - 35s 116ms/step - loss: 5.4646 - val_loss: 5.2783\n",
      "Epoch 3/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 5.1366 - val_loss: 4.9130\n",
      "Epoch 4/50\n",
      "301/301 [==============================] - 35s 117ms/step - loss: 4.7432 - val_loss: 4.5844\n",
      "Epoch 5/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 4.4203 - val_loss: 4.3647\n",
      "Epoch 6/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 4.1608 - val_loss: 4.1768\n",
      "Epoch 7/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 3.9440 - val_loss: 4.0507\n",
      "Epoch 8/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 3.7599 - val_loss: 3.9575\n",
      "Epoch 9/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 3.6034 - val_loss: 3.8870\n",
      "Epoch 10/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 3.4701 - val_loss: 3.8334\n",
      "Epoch 11/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 3.3501 - val_loss: 3.7891\n",
      "Epoch 12/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 3.2448 - val_loss: 3.7642\n",
      "Epoch 13/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 3.1497 - val_loss: 3.7360\n",
      "Epoch 14/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 3.0631 - val_loss: 3.7192\n",
      "Epoch 15/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 2.9816 - val_loss: 3.7003\n",
      "Epoch 16/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 2.9077 - val_loss: 3.6972\n",
      "Epoch 17/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 2.8398 - val_loss: 3.6897\n",
      "Epoch 18/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 2.7758 - val_loss: 3.6873\n",
      "Epoch 19/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 2.7149 - val_loss: 3.6838\n",
      "Epoch 20/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 2.6583 - val_loss: 3.6862\n",
      "Epoch 21/50\n",
      "301/301 [==============================] - 36s 118ms/step - loss: 2.6044 - val_loss: 3.6878\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 107\n",
    "hidden_size = 215\n",
    "encoder = Encoder(src_vocab, embed_dim, hidden_size)\n",
    "decoder = Decoder(tar_vocab, embed_dim, hidden_size)\n",
    "\n",
    "\n",
    "enc_inputs = Input(shape=(text_max_len,))\n",
    "dec_inputs = Input(shape=(None,))\n",
    "\n",
    "enc_output, state_h, state_c = encoder(enc_inputs)\n",
    "dec_outputs, _, _ = decoder(dec_inputs, enc_output, initial_state=[state_h, state_c])\n",
    "\n",
    "model = Model([enc_inputs, dec_inputs], dec_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8d84df3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde3060",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ee33bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4b966bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=enc_inputs, outputs=[enc_output, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb_layer = Embedding(tar_vocab, embed_dim)\n",
    "dec_emb2 = dec_emb_layer(dec_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
    "# 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "\n",
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [dec_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "59ae0b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    text_max_len = 50\n",
    "    summary_max_len = 8\n",
    "    \n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostk']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostk'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostk'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "86ae8615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2head(input_seq):\n",
    "    target_word_index = tar_tokenizer.word_index\n",
    "    target_index_to_word = tar_tokenizer.index_word\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=target_word_index['sostk']) and i!=target_word_index['eostk']):\n",
    "            temp = temp + target_index_to_word[i]+' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "16429d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word_index = tar_tokenizer.word_index\n",
    "target_word_index['sostk']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849008a",
   "metadata": {},
   "source": [
    "Case1) stopwords True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b051a532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : speaking experience working rajinikanth film kaala actress huma qureshi said simple human take stardom seriously disciplined meet question intimidated added huma said cannot begin learnt \n",
      "실제 요약 : rajinikanth is simple he does not take stardom seriously huma \n",
      "예측 요약 :  cooperation cooperation cooperation digital digital iraq iraq\n",
      "\n",
      "\n",
      "원문 : cricket australia said look verbal spat took place australian vice captain david warner south african wicketkeeper quinton de kock first test sunday cctv footage shows exchange duo players climbed dressing rooms tea break day \n",
      "실제 요약 : warner de kock in exchange during tea break \n",
      "예측 요약 :  maradona maradona maradona maradona maradona jackman jackman\n",
      "\n",
      "\n",
      "원문 : pm narendra modi friday tweeted enquired health dmk president karunanidhi daughter kanimozhi son mk stalin adding praying quick recovery offered assistance required family comes kauvery hospital said 94 year old leader health condition slightly declined \n",
      "실제 요약 : pm modi for karunanidhi health offers assistance \n",
      "예측 요약 :  join join join join join join join\n",
      "\n",
      "\n",
      "원문 : 14 year old boy hyderabad booked allegedly recording videos taking pictures women taking bath hostel adjacent building incident reportedly came light 22 year old student hostel filed complaint police said 000 videos pictures recovered boy tablet \n",
      "실제 요약 : 14 yr old records videos of women taking bath in hostel booked \n",
      "예측 요약 :  bn bn bn bn bn bn bn\n",
      "\n",
      "\n",
      "원문 : pope francis revealed sought help 42 leader order argentina six months went week clarify things pope said disclosure could challenge perception sought treatment weak added \n",
      "실제 요약 : pope reveals he sought help from \n",
      "예측 요약 :  baraat baraat baraat join join join feedback\n",
      "\n",
      "\n",
      "원문 : union minister state jitendra singh said mainstream politicians kashmir cannot go toilet without taking permission hurriyat conference get permission even remain lives added earlier governor satya pal malik said hurriyat go toilet without asking pakistan \n",
      "실제 요약 : leaders cannot go to toilet without asking hurriyat mos \n",
      "예측 요약 :  kuldeep kuldeep kuldeep kuldeep kuldeep kuldeep kuldeep\n",
      "\n",
      "\n",
      "원문 : new zealand government wednesday announced plans tighten access skilled work visas help get jobs ahead migrants new measures aim solve problems housing shortages road congestion overcrowding new zealand due record high levels migration comes day australia abolished skilled visa programme \n",
      "실제 요약 : new zealand restricts worker visas \n",
      "예측 요약 :  fewer fewer fewer fewer fewer fewer fewer\n",
      "\n",
      "\n",
      "원문 : event interacting olympic bronze medalist boxer vijender singh congress vice president rahul gandhi revealed black belt form japanese martial art involving traditional weapons gandhi also agreed suggestion vijender put videos sporting activities social media encourage people \n",
      "실제 요약 : am black belt in martial rahul gandhi tells vijender \n",
      "예측 요약 :  brain brain brain brain brain software brain\n",
      "\n",
      "\n",
      "원문 : least 23 inmates including woman tested hiv positive gorakhpur district jail uttar pradesh past eight months jail superintendent said undergoing treatment brd medical college superintendent added jail authorities however reveal inmates contracted disease \n",
      "실제 요약 : 23 inmates test positive for hiv in past months in up jail \n",
      "예측 요약 :  multi ugly ugly ugly ugly vows vows\n",
      "\n",
      "\n",
      "원문 : delhi high court cancelled issued warrant sanjiv gupta former managing director defunct online retailer warrant issued earlier month gupta apparently failed appear investigating alleged fraud however gupta counsel claimed filed statement earlier april \n",
      "실제 요약 : delhi hc cancels warrant against former md \n",
      "예측 요약 :  maritime maritime maritime maritime maritime maritime maritime\n",
      "\n",
      "\n",
      "원문 : many 000 chickens burnt alive poultry farm uttar pradesh shamli district police said tuesday incident happened electrical wire fell roof shed leading massive fire fire controlled help villagers owner poultry farm said \n",
      "실제 요약 : 000 die after farm catches fire in up \n",
      "예측 요약 :  salaries built built built built built built\n",
      "\n",
      "\n",
      "원문 : cinema hall dublin held dog friendly film screening sunday ahead release new animated movie ireland pet owners attended screening dogs given blankets special snacks speaking dogs organiser said sat seemed really enjoy action \n",
      "실제 요약 : cinema hall lets owners attend film with their dogs \n",
      "예측 요약 :  baraat news news news news news news\n",
      "\n",
      "\n",
      "원문 : 15 year old boy bengaluru receiving treatment addiction online game playerunknown battlegrounds boy started missing school due gaming parents took clinic deals technology based doctors diagnosed gaming disorder stating difficult proceed initially boy unwilling recognise problem \n",
      "실제 요약 : 15 yr old bengaluru boy gets treated for addiction to pubg \n",
      "예측 요약 :  express fix fix fix bn express express\n",
      "\n",
      "\n",
      "원문 : actor khan talking nepotism said everybody coming used influence help loved ones keep loved ones better position added merely human nature let us blow things proportion said industry based survival fittest \n",
      "실제 요약 : in wood uses influence to help loved ones \n",
      "예측 요약 :  godman godman godman godman godman iraq iraq\n",
      "\n",
      "\n",
      "원문 : supreme court lawyer former mizoram governor swaraj kaushal tweeted nothing like marital rape homes become police stations husbands jail house kaushal husband foreign minister sushma swaraj claimed comes government told court criminalising marital rape might put family system stress \n",
      "실제 요약 : nothing like marital rape sushma husband swaraj kaushal \n",
      "예측 요약 :  refuses refuses refuses refuses refuses refuses refuses\n",
      "\n",
      "\n",
      "원문 : condemning uk terror attack killed 22 people injured 59 others iranian foreign ministry spokesman said artificial alliances would stop expansion cancerous terrorism world terrorism uprooted avoiding double standards added notably us claims iran supports terrorism iran claims saudis fund militants \n",
      "실제 요약 : iran criticises west artificial with gulf \n",
      "예측 요약 : \n",
      "\n",
      "\n",
      "원문 : trainee aircraft indian air force wednesday crashed telangana district pilot reportedly sustained injuries shifted hospital treatment cause accident yet ascertained court inquiry investigate cause accident iaf pro anupam banerjee said \n",
      "실제 요약 : iaf trainee aircraft crash lands in telangana pilot injured \n",
      "예측 요약 :  pills pills pills pills venture treat treat\n",
      "\n",
      "\n",
      "원문 : us based scientists successfully tested artificial premature babies animal trials eight prematurely born equivalent 23 weeks human pregnancy placed uterus like found develop normally four weeks doctors claim approach could help babies born early cannot breathe fight infection without medical help \n",
      "실제 요약 : scientists successfully grow in artificial \n",
      "예측 요약 :  challenged challenged challenged challenged challenged challenged challenged\n",
      "\n",
      "\n",
      "원문 : sharing experience working late actress sridevi rishi kapoor said think ever female actor bollywood attained glory heights said complete actor fabulous dancer person could switch faces rishi worked sridevi films like chandni \n",
      "실제 요약 : no wood actress such like sridevi rishi \n",
      "예측 요약 :  cooperation cooperation cooperation cooperation cooperation cooperation cooperation\n",
      "\n",
      "\n",
      "원문 : camera footage captured moment roof airport china partially collapsed due extreme weather sunday passengers could seen running away site although one wounded incident meanwhile weather said winds reached speeds 30 metres per second \n",
      "실제 요약 : chinese airport roof collapses during storm \n",
      "예측 요약 :  spotted spotted spotted spotted spotted spotted spotted\n",
      "\n",
      "\n",
      "원문 : fox news show host called upcoming summit us president donald trump north korean leader kim jong un meeting two air however host later apologised saying mean reacting gaffe twitter user wrote fox news called trump dictator finally intellectual reporting \n",
      "실제 요약 : us news channel host calls trump dictator \n",
      "예측 요약 :  dhaaga dhaaga dhaaga dhaaga dhaaga dhaaga minded\n",
      "\n",
      "\n",
      "원문 : supreme court refused extend july 15 deadline payment crore sahara group dedicated sebi sahara refund account firm far deposited â¹1 500 crore refund account towards assurance payment â¹2 000 crore sahara asked pay back money raised illegally investors \n",
      "실제 요약 : supreme court denies sahara more time to deposit crore \n",
      "예측 요약 :  pak pak pak pak pak rd rd\n",
      "\n",
      "\n",
      "원문 : condoling demise former pm atal bihari vajpayee pakistan pm designate imran khan said establishing peace really honour legacy atal bihari vajpayee death vajpayee sahab south asian politics left huge political vacuum political differences sides want peace added \n",
      "실제 요약 : indo pak peace the only way to honour vajpayee imran khan \n",
      "예측 요약 :  samajwadi samajwadi samajwadi samajwadi samajwadi samajwadi samajwadi\n",
      "\n",
      "\n",
      "원문 : birth anniversary mahatma gandhi tuesday congress working committee called second freedom struggle pm narendra modi led government combat divisive politics ideology hate violence committee held meeting ashram congress held quit india call british rule 1942 \n",
      "실제 요약 : congress calls for 2nd freedom struggle against bjp govt \n",
      "예측 요약 :  dental asean asean asean dental dental dental\n",
      "\n",
      "\n",
      "원문 : delhi recorded 52 increase drunk driving cases 2018 compared last year according police records january may year many 15 450 motorists prosecuted drunk driving 000 vehicles impounded seized 80 accidents due drunken driving occur officials said \n",
      "실제 요약 : delhi records 52 rise in drunk driving cases this year \n",
      "예측 요약 :  assist assist assist assist assist assist assist\n",
      "\n",
      "\n",
      "원문 : many 32 labourers jharkhand allegedly held hostage saudi arabia forced work company without wages returned india following intervention ministry external affairs discussing matter union minister jayant sinha said today every indian abroad lives assurance country stands \n",
      "실제 요약 : 32 labourers return to india from saudi after mea intervenes \n",
      "예측 요약 :  adopt assange human human akhtar icse icse\n",
      "\n",
      "\n",
      "원문 : nasa juno spacecraft revealed giant cyclone jupiter north pole eight smaller another image depicted cyclone south pole surrounded five 000 km suggesting polar magnetic fields central storm may contain core high pressure high temperature rocks perhaps water said project scientist \n",
      "실제 요약 : nasa probe shows multiple storms over jupiter north pole \n",
      "예측 요약 :  canteen mba mba mba mba mba mba\n",
      "\n",
      "\n",
      "원문 : india second largest services firm infosys said fixed november record date â¹13 000 crore share buyback programme share buyback first company 36 year long history added buyback proposal approved board august 19 shareholders october \n",
      "실제 요약 : infosys fixes nov as record date for â¹13 000 crore buyback \n",
      "예측 요약 :  turban turban turban these these spiders spiders\n",
      "\n",
      "\n",
      "원문 : winter olympics officials confirmed pyeongchang winter games hit cyber attack opening ceremony officials refused reveal origin cyber attack official pyeongchang 2018 site stopped working start opening ceremony took almost 12 hours recover \n",
      "실제 요약 : winter olympics hit by cyber attack officials confirm \n",
      "예측 요약 :  cooking cooking cooking cooking targeting targeting dena\n",
      "\n",
      "\n",
      "원문 : vending machine dispenses packets customers emotional needs aim increase mental health awareness come australian city sydney designed mental health professionals artists packets sold machine cost names like purpose belonging packets contain notes maps origami stars written prompts \n",
      "실제 요약 : vending machine packets for buyers \n",
      "예측 요약 :  pornstar pornstar pornstar pornstar pornstar pornstar individual\n",
      "\n",
      "\n",
      "원문 : police tuesday filed case unnatural death father witness kerala nun rape case bishop franco mulakkal found dead house jalandhar case filed based complaint brother alleged killed giving statement mulakkal \n",
      "실제 요약 : unnatural death case filed after witness in nun rape case dies \n",
      "예측 요약 :  digital digital digital fixes fixes fixes fixes\n",
      "\n",
      "\n",
      "원문 : reliance industries signed deal buy music streaming service integrate create music streaming platform valued billion three co founders continue leadership roles deal led reliance jio director akash ambani approximately three platform owned reliance \n",
      "실제 요약 : reliance jio to create bn music streaming platform \n",
      "예측 요약 :  sept sept sept sept sept equal equal\n",
      "\n",
      "\n",
      "원문 : actress sanya malhotra played babita phogat dangal choreographed song featuring aamir khan upcoming film secret superstar talking experience sanya said dreams could imagined something wonderful aamir extended cameo appearance film teenage girl aspiring singer \n",
      "실제 요약 : dangal actress sanya aamir in secret superstar \n",
      "예측 요약 :  nipah map map map map map map\n",
      "\n",
      "\n",
      "원문 : zaira wasim known starring film dangal revealed diagnosed depression four half years ago adding five every day anxiety attacks suicidal thoughts part phase zaira said remember told thing depression happens people 25 \n",
      "실제 요약 : suffered from depression had suicidal thoughts zaira wasim \n",
      "예측 요약 :  sostk sostk sostk sostk sostk sostk sostk\n",
      "\n",
      "\n",
      "원문 : ministry civil aviation said reviewing private carriers indigo spicejet decision levy fee web check ins comes response passengers complaints indigo said revised policies making seats selected online chargeable even middle seats spared daylight robbery user tweeted \n",
      "실제 요약 : govt to review airline web check in fee following complaints \n",
      "예측 요약 :  misa misa misa misa misa misa misa\n",
      "\n",
      "\n",
      "원문 : cab hailing startup uber us based rival lyft wednesday raised additional 600 million series financing round led fidelity management research company taking valuation 15 billion startup value doubled past 14 months founded 2012 lyft raised billion since inception \n",
      "실제 요약 : uber rival lyft raises 600 million at 15 billion valuation \n",
      "예측 요약 :  viking viking viking viking viking viking slap\n",
      "\n",
      "\n",
      "원문 : support 122 mlas needed form government 243 seat bihar assembly nitish kumar face floor test friday backing jd 71 mlas bjp 53 mlas nda partners mlas apart two independent mlas extended support new alliance taking total 131 \n",
      "실제 요약 : what are nitish kumar in friday floor test \n",
      "예측 요약 :  options options options options options options daimler\n",
      "\n",
      "\n",
      "원문 : interview social media damani director documentary dying people delhi dheeraj sharma slammed making memes 13 year old drug addict kamlesh minute video interview kamlesh gone viral social media led creation memes statements \n",
      "실제 요약 : director slams memes made on \n",
      "예측 요약 :  digital digital digital digital digital digital digital\n",
      "\n",
      "\n",
      "원문 : us president donald trump referred popular series game thrones announce new sanctions iran come effect november trump tweeted picture words sanctions coming written font used show phrase tweaked version series winter coming tagline \n",
      "실제 요약 : trump uses game of thrones reference to reveal iran sanctions \n",
      "예측 요약 :  demonetised demonetised demonetised demonetised demonetised demonetised demonetised\n",
      "\n",
      "\n",
      "원문 : hollywood filmmaker christopher nolan said honoured film memento inspired aamir khan 2008 film adding watch point nolan said heard successful heard people liked nolan also said watched kamal haasan films ray bengali film \n",
      "실제 요약 : honoured my film inspired aamir \n",
      "예측 요약 :  cooperation cooperation discussion discussion discussion discussion discussion\n",
      "\n",
      "\n",
      "원문 : woman west bengal gave birth healthy baby hours lab report said carrying dead foetus according family woman experienced labour pains visited laboratory whose report read intra death 32 weeks days family lodged police complaint laboratory \n",
      "실제 요약 : woman gives birth hours after report says foetus is dead \n",
      "예측 요약 :  jinnah jinnah jinnah jinnah jinnah jinnah jinnah\n",
      "\n",
      "\n",
      "원문 : rajasthan congress expelled 28 leaders contesting official candidates party upcoming assembly elections expelled leaders include nine former mlas former union minister singh action taken direction state congress chief sachin pilot congress spokesperson said \n",
      "실제 요약 : raj cong expels 28 for contesting against party candidates \n",
      "예측 요약 :  spotted spotted spotted corpse corpse corpse corpse\n",
      "\n",
      "\n",
      "원문 : karnataka cabinet minister ut refused comply central government ban red beacons vip vehicles chief minister asks remove red beacon light obey instruction remove said minister union cabinet decided ban use red beacons effect may \n",
      "실제 요약 : will remove red beacon when cm asks me to karnataka min \n",
      "예측 요약 :  dinner dinner dinner dinner dinner dinner dinner\n",
      "\n",
      "\n",
      "원문 : akhil bharatiya vidyarthi parishad activist amit goswami offered â¹1 lakh anyone would chop arms sunil singh directed game ayodhya goswami claimed film wrongly shows statue lord rama installed mosque hindus kill see anywhere goswami added \n",
      "실제 요약 : abvp member offers â¹1l to game of ayodhya director \n",
      "예측 요약 :  daily daily daily daily daily lenin lenin\n",
      "\n",
      "\n",
      "원문 : union minister state electronics information technology pp chaudhary tuesday said custom triple talaq practised muslim men divorce wives indian constitution nothing constitution according cannot difference basis religion caste gender added \n",
      "실제 요약 : triple talaq is against indian constitution union minister \n",
      "예측 요약 :  expecting adviser adviser adviser unnecessary unnecessary unnecessary\n",
      "\n",
      "\n",
      "원문 : university texas researchers discovered 20 new species deep sea microbes consume methane survive grow microbes found deep sea sediments located basin gulf california prevent greenhouse gases released atmosphere could degrade oil harmful chemicals researcher said \n",
      "실제 요약 : new species of that feed on found \n",
      "예측 요약 :  aamir aamir population population dowry dowry dowry\n",
      "\n",
      "\n",
      "원문 : amid heavy rains city mumbai police tweeted gif featuring lyrics theme song tv series friends gif shows police force helping citizens says rains start pour reacting post user tweeted excellent job mumbai police proud \n",
      "실제 요약 : mumbai police tweets rain message with friends reference \n",
      "예측 요약 :  nitish nitish nitish nitish nitish nitish nitish\n",
      "\n",
      "\n",
      "원문 : mcdonald india wednesday said challenged national company law appellate tribunal nclt order reinstated estranged partner vikram bakshi managing director joint venture cprl bakshi ousted post md august 2013 following approached nclt restored bakshi md july 13 2017 \n",
      "실제 요약 : mcdonald challenges bakshi as md \n",
      "예측 요약 :  cycling cycling cycling sewer sewer cycling rugby\n",
      "\n",
      "\n",
      "원문 : actress preity zinta completed 19 years bollywood monday shared collage instagram captioned happy birthday movies thanked director mani ratnam co stars debut film dil se shah rukh khan manisha koirala unbelievable experience film released day 1998 \n",
      "실제 요약 : my happy birthday in movies preity on 19 years in bollywood \n",
      "예측 요약 :  welcome welcome welcome welcome welcome welcome welcome\n",
      "\n",
      "\n",
      "원문 : five people died due heavy rains karnataka state bjp president bs yeddyurappa said congress government karnataka anti development cm siddaramaiah responsible every single death meanwhile chief minister siddaramaiah said yeddyurappa politicise issues asked rains bjp government \n",
      "실제 요약 : karnataka cm responsible for every single death yeddyurappa \n",
      "예측 요약 :  blind blind blind blind blind blind blind\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2head(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c3412",
   "metadata": {},
   "source": [
    "Case2) stopwords False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f8c3fab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : us federal judge on tuesday blocked president donald trump executive order that sought to withhold federal funds from sanctuary cities saying the president has no authority to attach new conditions to federal spending the administration was taking action to appeal the ruling and will win at the supreme court level at some point white house officials said \n",
      "실제 요약 : judge blocks trump order to restrict sanctuary city funds \n",
      "예측 요약 :  cola cola cola cola cola cola cola\n",
      "\n",
      "\n",
      "원문 : former rbi governor raghuram rajan has blamed over optimistic bankers growth slowdown and slow decision making by governments for bad loan crisis he added that larger number of bad loans originated between 2006 and 2008 when economic growth was strong it is at such times that banks make mistakes they past growth and performance to the future rajan further said \n",
      "실제 요약 : over responsible for bad loans rajan \n",
      "예측 요약 :  tapes tapes tapes tapes tapes exposed exposed\n",
      "\n",
      "\n",
      "원문 : the hong kong electoral office has reported the theft of two laptops containing information of hong kong 37 lakh registered voters the devices were reportedly stolen from locked room which was backup venue for election of hong kong chief executive held over the weekend the information stolen reportedly includes voter id card numbers addresses and phone numbers \n",
      "실제 요약 : laptops with data of 37 lakh people stolen in hong kong \n",
      "예측 요약 :  siraj siraj siraj siraj siraj siraj photosynthesis\n",
      "\n",
      "\n",
      "원문 : pakistan has issued its first third gender passport to transgender activist who hailed the move as step forward for the marginalised community in the conservative country the activist said the new passport would help her campaign globally on behalf of her community notably she earlier held passport which described her gender as male \n",
      "실제 요약 : pakistan issues its first transgender passport \n",
      "예측 요약 :  highlight bse bse bse bse bse bse\n",
      "\n",
      "\n",
      "원문 : american aerospace startup rocket lab earlier this week launched new zealand first satellite humanity star sphere made with 65 reflective panels orbiting the earth every 90 minutes the satellite would be visible to the naked eye at night as it passes overhead rocket lab described humanity star as reminder to all about our fragile place in the universe \n",
      "실제 요약 : new zealand first satellite to be visible to the naked eye \n",
      "예측 요약 :  amendment amendment amendment amendment amendment amendment amendment\n",
      "\n",
      "\n",
      "원문 : an association representing the members of the indian administrative service has said the officers will adopt families of security personnel who lost their lives in maoist anti terror operations or law and order duties the bureaucrats will approach such families within their area of posting and act as to help them get their dues including jobs and pensions \n",
      "실제 요약 : ias officers to adopt martyred security personnel families \n",
      "예측 요약 :  5g educate educate educate educate educate educate\n",
      "\n",
      "\n",
      "원문 : delhi cm arvind kejriwal on sunday questioned pm narendra modi on whether talking about hindus and muslims would help india become the number one country in the world adding that only education would make india number one he said if pm modi is talking about hindu muslims even after four years it means his government has achieved nothing he added \n",
      "실제 요약 : will hindu muslim talk make india number kejriwal to pm \n",
      "예측 요약 :  rated rated rated rated rated rated rated\n",
      "\n",
      "\n",
      "원문 : 38 year old woman in maharashtra district died due to excessive bleeding after she delivered stillborn baby in her tenth pregnancy the woman who used to run paan shop was mother to seven daughters one of whom had passed away her family wanted boy and she conceived again reportedly under family pressure \n",
      "실제 요약 : maha woman dies delivering child in 10th pregnancy \n",
      "예측 요약 :  opposes opposes opposes newly newly newly newly\n",
      "\n",
      "\n",
      "원문 : the income tax department conducted search and recovery operation at the residence of jailed aiadmk leader sasikala at garden in chennai on friday laptop desktop and pen drives were reportedly seized from her room this comes after raids on sasikala kin and jaya tv premises unearthed unaccounted income of â¹1 400 crore \n",
      "실제 요약 : dept conducts search operation at sasikala residence \n",
      "예측 요약 :  seva burger burger burger burger burger jinnah\n",
      "\n",
      "\n",
      "원문 : new body trend named hip dip has gone viral on instagram as many women are sharing photos and videos about it hip dip refers to the that some women have in the area where their hips meet their thighs embrace your body and know that whether you have hip or not you are beautiful wrote user \n",
      "실제 요약 : hip dip body trend goes viral on instagram \n",
      "예측 요약 :  netanyahu netanyahu lauds lauds lauds lauds lauds\n",
      "\n",
      "\n",
      "원문 : the united nations has condemned the execution of 38 jihadists belonging to isis and al qaeda by iraq on thursday and called for an immediate halt to the mass execution of prisoners in the country calling iraq criminal justice system flawed un envoy elizabeth said that the executions raised the prospect of irreversible of justice and violations of rights \n",
      "실제 요약 : un condemns iraq execution of 38 isis al qaeda terrorists \n",
      "예측 요약 :  whitewash whitewash whitewash whitewash silver silver silver\n",
      "\n",
      "\n",
      "원문 : facebook failed to monitor its partners or the device makers to whom it granted access to the personal data of its users according to report by the new york times the oversight was reportedly identified by government approved privacy monitor in 2013 but was never revealed earlier facebook admitted it shared user data with companies including microsoft and apple \n",
      "실제 요약 : fb did not check how its partners handled user data report \n",
      "예측 요약 :  imposed imposed imposed imposed imposed imposed imposed\n",
      "\n",
      "\n",
      "원문 : filmmaker kunal kohli revealed that aamir khan said will give you three names and that is kajol kajol and kajol when asked who should star opposite him in the film kunal directorial completed eleven years on friday speaking on the occasion he added having them on board remains my best memory of \n",
      "실제 요약 : will give names that is kajol aamir on actress for \n",
      "예측 요약 :  servants servants servants servants servants servants dances\n",
      "\n",
      "\n",
      "원문 : former vice president hamid ansari on wednesday claimed the success of bjp is and regional rather than at the national level and added saffron ideology seeks to the democratic values of diversity and he said the bjp led government had failed in its economic policies in the last four years and farmers and unemployed youth were expressing grievances \n",
      "실제 요약 : saffron ideology seeks to democratic ex vp \n",
      "예측 요약 :  certificates 10l 10l vaccine vaccine vaccine vaccine\n",
      "\n",
      "\n",
      "원문 : indian ethical hacker anand prakash has revealed being awarded â¹3 25 lakh by twitter last year for discovering bug that let him tweet from any account on the microblogging platform the bug also allowed him to post videos photos and delete the ones already posted from any twitter account it also let him access private files uploaded on twitter \n",
      "실제 요약 : indian rewarded with â¹3 25 lakh for twitter bug \n",
      "예측 요약 :  shocks shocks shocks shocks shocks shocks shocks\n",
      "\n",
      "\n",
      "원문 : comedian kapil sharma took to instagram to announce that he will get married to his girlfriend ginni chatrath on december 12 need your blessings kapil wrote while sharing picture of the wedding card the wedding will take place in jalandhar and will be followed by an akhand path at ginni house on december 30 \n",
      "실제 요약 : kapil sharma confirms marriage with girlfriend on december 12 \n",
      "예측 요약 :  assad assad assad assad assad rented rented\n",
      "\n",
      "\n",
      "원문 : man died on tuesday after he fell off during human pyramid formation while celebrating dahi handi in maharashtra area the deceased rohan gopinath reportedly suffered seizure during the formation and was rushed to nearby hospital where he was declared dead on arrival the police has registered case of accidental death \n",
      "실제 요약 : man dies after falling during maharashtra event \n",
      "예측 요약 :  demon demon demon demon demon demon demon\n",
      "\n",
      "\n",
      "원문 : taking dig at former finance minister yashwant sinha finance minister arun jaitley on thursday called him job applicant at 80 sinha had published an article claiming the economy was on spiral blaming jaitley for failures like demonetisation and gst jaitley added he does not have the luxury of being former finance minister and cannot forget past records \n",
      "실제 요약 : jaitley takes dig at sinha calls him job at 80 \n",
      "예측 요약 :  prannoy region region ian ian ian ian\n",
      "\n",
      "\n",
      "원문 : after acquiring broadcast rights of indian cricket team home series for the next five years for â¹6 138 crore star india now owns â¹22 crore worth of media rights for cricket in india it had acquired the ipl global media rights with consolidated bid of â¹16 347 crore last year star india also owns broadcast rights of all major icc tournaments \n",
      "실제 요약 : star india owns rights worth â¹22 crore of indian cricket \n",
      "예측 요약 :  flood flood flood flood flood flood flood\n",
      "\n",
      "\n",
      "원문 : finance minister arun jaitley said the government was seeking reserve bank of india surplus for poverty programmes and state run banks and not to meet fiscal deficit modi government has the best track record of keeping fiscal deficit under check he added jaitley had assured government is on track to meet fiscal deficit target of of gdp \n",
      "실제 요약 : govt seeking rbi reserves for poverty jaitley \n",
      "예측 요약 :  2010 2010 2010 organ organ organ organ\n",
      "\n",
      "\n",
      "원문 : at least 11 people were injured after car ploughed into pedestrians outside london natural history museum on saturday according to reports man was arrested at the scene following the incident describing the incident as collision police said it is not being treated as terrorist incident at this stage while we establish what has happened \n",
      "실제 요약 : car ploughs into crowd in london injures 11 \n",
      "예측 요약 :  opposes aspirants aspirants aspirants aspirants modern modern\n",
      "\n",
      "\n",
      "원문 : reacting to pakistani player tying shoelaces of indian vice captain shubman gill in the semi final of 19 world cup on tuesday user wrote divided by boundaries united by cricket another user wrote they are rivals not enemies moment of the match these moments have won many hearts we expect these type of moments in every match tweet read \n",
      "실제 요약 : moment of match tweets user on pak player tying indian \n",
      "예측 요약 :  124 124 124 124 124 124 124\n",
      "\n",
      "\n",
      "원문 : shubman gill who slammed 372 runs in the 2018 under 19 world cup became the fourth indian to be awarded man of the tournament at an icc under 19 world cup yuvraj singh had won the award in the 2000 edition for scoring 203 runs and taking 12 wickets shikhar dhawan and cheteshwar pujara achieved the feat in 2004 and 2006 respectively \n",
      "실제 요약 : which indians have won man of tournament award at 19 \n",
      "예측 요약 :  79 ajmer ajmer ajmer ajmer ajmer finale\n",
      "\n",
      "\n",
      "원문 : delhi chief minister arvind kejriwal on saturday said the alleged move to rename ramlila maidan after late pm atal bihari vajpayee will not fetch the bjp any votes but changing the name of the prime minister might he tweeted bjp should try changing the name of the prime minister to get some votes as people are not voting for him \n",
      "실제 요약 : try changing name of pm you may get votes kejriwal to bjp \n",
      "예측 요약 :  pole pole healthcare healthcare healthcare healthcare healthcare\n",
      "\n",
      "\n",
      "원문 : jnu dean of students umesh ashok kadam on tuesday filed an fir against 17 students including jnu students union president geeta kumari alleging that they assaulted him the university administration had claimed that the students who were protesting against hostel fee hike last week barged into the dean office and manhandled and verbally abused him \n",
      "실제 요약 : jnu dean files fir against 17 students for assaulting him \n",
      "예측 요약 :  contract solar solar bright bright bright bright\n",
      "\n",
      "\n",
      "원문 : german bike shop is selling featuring engine parts from vintage harley davidson motorcycles lodged in the bottles for over â¹80 000 according to the company press release each engine part gets thorough cleaning before it is sealed with tin alloy to ensure that the liquor inside the bottle is food safe \n",
      "실제 요약 : with harley davidson parts sells for over â¹80 000 \n",
      "예측 요약 :  dangerous dangerous paintings paintings paintings paintings paintings\n",
      "\n",
      "\n",
      "원문 : nine cryptocurrency hedge funds tracked by research firm gave combined returns of 167 in 2017 compared to bitcoin 400 gain in contrast hedge funds globally returned on average however the digital currency fund which gained nearly 500 last year had warned its clients that they should invest only an amount they can afford to lose \n",
      "실제 요약 : crypto hedge funds saw over 100 returns in 2017 \n",
      "예측 요약 :  women women women women women women women\n",
      "\n",
      "\n",
      "원문 : vogue us august edition featuring model gigi hadid and boyfriend zayn malik has been slammed for its take on gender the cover story presents them as gender fluid who share each other clothing wearing your shirt does not make you gender fluid user tweeted is an identity not fu king fashion trend read another comment \n",
      "실제 요약 : gigi zayn vogue cover slammed for take on gender \n",
      "예측 요약 :  milind milind milind milind milind milind milind\n",
      "\n",
      "\n",
      "원문 : muslims have started protesting against the uttar pradesh government plan to make marriage registration mandatory and termed it as un islamic muslim marriages are only registered at the office of the waqf board of up as per the documents muslim leader haji said there is no need to register marriages again merely to satisfy government he added \n",
      "실제 요약 : muslims protest plan to make marriage registration mandatory \n",
      "예측 요약 :  crops crops then then then slip slip\n",
      "\n",
      "\n",
      "원문 : former haryana chief minister om prakash chautala grandson dushyant chautala on sunday launched new political outfit janta party in haryana jind hisar mp dushyant was recently expelled from indian national lok dal on the grounds of indiscipline addressing rally dushyant urged the public to oust the congress the bjp and the from power \n",
      "실제 요약 : after split launches party \n",
      "예측 요약 :  edited farm farm 10l 10l 10l 10l\n",
      "\n",
      "\n",
      "원문 : us president donald trump on thursday said that russia iran syria and others will have to fight isis without the us following his decision to withdraw american troops from syria he added that these countries are not happy with his decision the us president further issued warning saying the islamic state is if they ever attack the us \n",
      "실제 요약 : russia iran syria will have to fight isis without us trump \n",
      "예측 요약 :  airport airport airport airport airport airport airport\n",
      "\n",
      "\n",
      "원문 : man has been arrested for allegedly using forged letters of external affairs minister sushma swaraj for helicopter tickets to the mata vaishno devi cave shrine said jammu police on saturday the police said the accused acquired these tickets through the quota based on forged letters of the office of sushma swaraj he sold the tickets in the black market \n",
      "실제 요약 : man uses letters of swaraj for helicopter tickets \n",
      "예측 요약 :  richard richard richard richard richard soccer soccer\n",
      "\n",
      "\n",
      "원문 : amid the ongoing lawsuit against uber for stealing google self driving car tech through ex executive anthony levandowski uber has claimed it knew levandowski possessed google data but not that he had stolen it google responded that the evidence clearly shows that stolen information has already made its way into uber technology notably uber has fired levandowski amid the dispute \n",
      "실제 요약 : we knew exec had google data not that it was stolen uber \n",
      "예측 요약 :  domestic domestic domestic domestic domestic psg nissan\n",
      "\n",
      "\n",
      "원문 : the johannesburg test match between india and south africa was the first instance of india pacers taking all 20 wickets in test jasprit bumrah was the pick of the bowlers with seven wickets followed by mohammad shami who took six other seven wickets were shared by ishant sharma and bhuvneshwar kumar while india fifth pacer hardik pandya went \n",
      "실제 요약 : indian take all 20 wickets in test for first time \n",
      "예측 요약 :  chandigarh chandigarh chandigarh chandigarh chandigarh chandigarh ajmer\n",
      "\n",
      "\n",
      "원문 : video of congress president rahul gandhi has surfaced online showing him helping photographer who fell down the stairs get up the photographer fell head first from steep stairs outside odisha airport following which several people including rahul rush to help him and quick action for the people in need comes as reflex to true leader congress tweeted \n",
      "실제 요약 : rahul helps photographer after he falls from stairs outside airport \n",
      "예측 요약 :  developers dismissals dismissals dismissals dismissals dismissals dismissals\n",
      "\n",
      "\n",
      "원문 : us president donald trump has slammed india for high import tariffs on high end motorcycles and threatened to impose reciprocal tax on motorcycles imported from india he added that the recent decision of india to reduce the customs duty from 75 to 50 was not enough at present us does not levy any tariff on indian motorcycle imports \n",
      "실제 요약 : trump threatens tax on from india \n",
      "예측 요약 :  disease unsafe unsafe disease disease dsp dsp\n",
      "\n",
      "\n",
      "원문 : the supreme court on tuesday deferred the hearing in the rohingya refugees deportation case to january 31 2018 two rohingya refugees had filed plea against the decision to deport rohingya muslims back to myanmar in the last hearing the court had ordered that no refugee should be deported till the next hearing in the case nn \n",
      "실제 요약 : sc hearing in rohingya deportation case to jan 31 \n",
      "예측 요약 :  bhi bhi bhi bhi bhi bhi bhi\n",
      "\n",
      "\n",
      "원문 : punjab chief minister amarinder singh had an attendance of only as lok sabha member according to prs legislative research singh who was also the deputy leader of congress in the lok sabha did not introduce any private member bill during his tenure the 75 year old had resigned as lok sabha member from amritsar just before the punjab assembly polls \n",
      "실제 요약 : punjab cm amarinder singh lok sabha attendance only \n",
      "예측 요약 :  rahman rahman rahman rahman rahman rahman rahman\n",
      "\n",
      "\n",
      "원문 : bhuvneshwar singh the youth wing leader of the group akhil bhartiya kshatriya mahasabha has announced that they will offer reward of â¹1 crore to anyone who burns deepika padukone alive over the ongoing padmavati row deepika should know how it feels like to be burnt alive the actress will never know the sacrifice of queen added singh \n",
      "실제 요약 : group offers â¹1 crore for burning deepika alive \n",
      "예측 요약 :  street street street street street street street\n",
      "\n",
      "\n",
      "원문 : ex ubs trader who was jailed for causing billion loss to the bank is set to be deported to his native ghana according to the uk immigration minister was released in 2015 after serving less than half his seven year sentence the 38 year old has lived in the uk since he was 12 but is ghanaian national \n",
      "실제 요약 : ex trader jailed for 3bn loss to be deported to ghana \n",
      "예측 요약 :  depp depp depp depp depp depp depp\n",
      "\n",
      "\n",
      "원문 : tribal man carried his wife on his shoulders and ran for over three kilometres to admit her to hospital in telangana after she allegedly consumed pesticide however she was declared brought dead the incident occurred when the couple reportedly realised rains had damaged their crop and they had incurred huge debts after taking land on lease \n",
      "실제 요약 : tribal man carries wife to hospital after she drinks poison \n",
      "예측 요약 :  supermarket supermarket supermarket supermarket supermarket supermarket supermarket\n",
      "\n",
      "\n",
      "원문 : china based alibaba founder jack ma will be starring in kung fu movie titled dao and will be produced by actor jet li the entrepreneur will play the role of master of an ancient art in the twenty minute movie it will also feature jet li as well as other notable actors including yen \n",
      "실제 요약 : alibaba founder jack ma to star in kung fu movie \n",
      "예측 요약 :  mice mice mice mice mice mice mice\n",
      "\n",
      "\n",
      "원문 : while protesting at the un headquarters in new york against the alleged human rights violations in pakistan who migrated to pakistan from india during 1947 partition called pakistan army generals war criminals the protesters claimed that thousands of innocent people of their community were killed in pakistan over the last three decades and many are held under illegal captivity \n",
      "실제 요약 : pakistan army are war criminals muslim immigrants \n",
      "예측 요약 :  promoting promoting promoting promoting promoting promoting promoting\n",
      "\n",
      "\n",
      "원문 : indian cricket team captain virat kohli has said that 20 time grand slam champion roger federer is his ultimate favorite he has his priorities set and he takes time off the game without worrying about criticism and then he wins grand slams at 36 he is defying all logic so that is something that totally love kohli added \n",
      "실제 요약 : federer my he is all kohli \n",
      "예측 요약 :  dropping dinesh dinesh dinesh dinesh dinesh kovind\n",
      "\n",
      "\n",
      "원문 : indian women team pacer jhulan goswami world cup semi final winning jersey will be displayed on the walls of sports museum in kolkata the 000 square feet museum features jerseys and memorabilia from sportspersons including roger federer sachin tendulkar and usain bolt among others this sporting memorabilia will inspire youngsters to take up sport goswami said \n",
      "실제 요약 : jhulan wc semis jersey to be displayed at sports museum \n",
      "예측 요약 :  parmanu parmanu parmanu parmanu parmanu parmanu parmanu\n",
      "\n",
      "\n",
      "원문 : the ministry of urban development has proposed bill that provides for life sentence or death penalty for any act of sabotage with the intent to cause in metro premises across india the metro rail bill 2017 further provides fine of â¹5 000 for drunk commuters and four year jail term for carrying guns inside the metro \n",
      "실제 요약 : bill proposes death penalty for \n",
      "예측 요약 :  international international international international contracts contracts contracts\n",
      "\n",
      "\n",
      "원문 : india defeated south africa by eight wickets in the sixth odi on friday becoming the second team to beat the proteas at their home in bilateral odi series before this south africa had lost only to australia in seven match series in 2002 the match saw captain virat kohli slam his 19th odi ton in successful \n",
      "실제 요약 : india hand sa their joint worst series defeat at home \n",
      "예측 요약 :  soros soros soros sameer sameer sameer sameer\n",
      "\n",
      "\n",
      "원문 : the us government spent 32 000 for the india visit of us president donald trump son donald trump jr reports citing us government records claimed the money was used to cover the costs of hotel rooms for trump jr security detail he was on business trip to india to promote his real estate business in the country \n",
      "실제 요약 : us paid money for trump jr india trip report \n",
      "예측 요약 :  how how disrupted disrupted disrupted disrupted disrupted\n",
      "\n",
      "\n",
      "원문 : ex australian captain steve smith father peter smith was filmed dumping his son cricket kit into the family garage after he was handed one year ban over the ball tampering scandal on being asked about steve condition peter said he will be fine he will survive earlier peter was seen steve during his first press conference in australia since the ball tampering scandal \n",
      "실제 요약 : he will survive steve smith dad dumps cricket kit in garage \n",
      "예측 요약 :  undersea undersea undersea undersea adding adding adding\n",
      "\n",
      "\n",
      "원문 : akshay kumar has said that he always wanted to work in and make socially relevant films while adding did not have enough money but now can he added even hollywood does not have single film on sanitary pads or menstrual hygiene people don want to make commercial films because they want to shy away from the issue \n",
      "실제 요약 : had no money to make films earlier akshay \n",
      "예측 요약 :  rouhani rouhani rouhani rouhani rouhani rouhani once\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2head(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3391683f",
   "metadata": {},
   "source": [
    "[이슈]    \n",
    "수정한 코드에 문제가 있는지 요약이 제대로 진행되지 않고 단어를 반복하는 결과를 보였다.   \n",
    "학습데이터에 stopwords 진행/비진행 비교를 해보고자하였으나, 위와 같은 이슈로 파악이 어렵다.   \n",
    "원인은 아래 진행한 < Summa을 이용해서 추출적 요약해보기 > 이슈와 같은 원인으로 사료된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c94dd5d",
   "metadata": {},
   "source": [
    "### Summa을 이용해서 추출적 요약해보기    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3a5fbbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a1dcd371",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b4eaada0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c108f6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pakistani singer rahat fateh ali khan has denied receiving any notice from the enforcement directorate over allegedly smuggling foreign currency out of india it would have been better if the authorities would have served the notice first if any and then publicised this reads press release issued on behalf of rahat the statement further called the allegation bizarre'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2870f356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data['text'][5]\n",
    "print('Summary:')\n",
    "print(summarize(data['text'][5], ratio=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de784df7",
   "metadata": {},
   "source": [
    "[이슈]  \n",
    "summarize가 data['text']에 대한 요약본이 출력되지 않는다. http://rare-technologies.com/the_matrix_synopsis.txt 데이터에 비해 길익가 짧은 data['text']가 원인이라고 생각하고 ratio를 조절하였으나, 변화가 없었다. 예상할 수 있는 원인은 다음과 같다.   \n",
    "- 텍스트 전처리 문제: 전처리나,문장이 제대로 구분되지 않으면 요약이 생성되지 않을 수 있다. 이전 단계에서 모델 요약이 잘되었기 때문에, 모두 전처리 문제에서 이슈가 발생했을 수 있다고 사료된다. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
